import os
import sys
from pathlib import Path
from itertools import combinations
from typing import Any, Dict, List, Tuple
from datetime import datetime
import json
from difflib import SequenceMatcher
import re

import numpy as np
from docx import Document
from openai import OpenAI
from tqdm import tqdm

# è®¾ç½®è¾“å‡ºç¼–ç ï¼Œé¿å… Windows æ§åˆ¶å°é»˜è®¤ GBK å¯¼è‡´ emoji/ç‰¹æ®Šå­—ç¬¦æ‰“å°å´©æºƒ
if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8', errors='replace')
        sys.stderr.reconfigure(encoding='utf-8', errors='replace')
    except Exception:
        pass

def _safe_print(msg: str):
    """åœ¨æ§åˆ¶å°ç¼–ç ä¸æ”¯æŒæ—¶ä¹Ÿä¸å´©æºƒï¼ˆæ‰“åŒ…/å‘½ä»¤è¡Œåœºæ™¯å¸¸è§ï¼‰ã€‚"""
    try:
        print(msg)
    except UnicodeEncodeError:
        # å»æ‰å¯èƒ½å¯¼è‡´å´©æºƒçš„å­—ç¬¦ï¼ˆå¦‚ emojiï¼‰
        print(msg.encode("utf-8", errors="replace").decode("utf-8", errors="replace"))

# å¼•å…¥ ImageAnalyzer
try:
    from image_analysis import ImageAnalyzer
except Exception:
    try:
        # å…¼å®¹ä»¥åŒ…æ–¹å¼å¯¼å…¥ï¼ˆimport document_sort.find_similar_filesï¼‰
        from .image_analysis import ImageAnalyzer  # type: ignore
    except Exception:
        ImageAnalyzer = None
        _safe_print("âš ï¸ æ— æ³•å¯¼å…¥ image_analysis æ¨¡å—ï¼Œå›¾ç‰‡æ·±åº¦åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")

try:
    from PyPDF2 import PdfReader
except ImportError:
    PdfReader = None

try:
    import pypdfium2 as pdfium
except ImportError:
    pdfium = None

try:
    from PIL import Image
except ImportError:
    Image = None

import base64
from io import BytesIO

# ============ é…ç½®éƒ¨åˆ† ============
# å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½ API keys
try:
    from config_loader import load_config
    config = load_config()
    DASHSCOPE_KEY = config.get('DASHSCOPE_API_KEY') or os.getenv("DASHSCOPE_API_KEY") or "dummy-key"
    DEEPSEEK_KEY = config.get('DEEPSEEK_API_KEY') or os.getenv("DEEPSEEK_API_KEY") or "dummy-key"
    EMBED_MODEL = config.get('EMBED_MODEL', 'text-embedding-v4')
    LLM_MODEL = config.get('CHAT_MODEL', 'deepseek-chat')
except ImportError:
    # å¦‚æœæ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œå›é€€åˆ°ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼
    DASHSCOPE_KEY = os.getenv("DASHSCOPE_API_KEY") or "dummy-key"
    DEEPSEEK_KEY = os.getenv("DEEPSEEK_API_KEY") or "dummy-key"
    EMBED_MODEL = "text-embedding-v4"
    LLM_MODEL = "deepseek-chat"

# é€šä¹‰åƒé—®ï¼ˆDashScopeï¼‰ç”¨äº Embeddingï¼›DeepSeek ç”¨äº Chat
# æ‰“åŒ…æ—¶ä½¿ç”¨ dummy keyï¼Œè¿è¡Œæ—¶ä¼šä» config.json é‡æ–°åŠ è½½
emb_client = OpenAI(api_key=DASHSCOPE_KEY, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
chat_client = OpenAI(api_key=DEEPSEEK_KEY, base_url="https://api.deepseek.com/v1")
# ä½¿ç”¨ç›¸å¯¹äºè„šæœ¬æ–‡ä»¶çš„è·¯å¾„ï¼Œé¿å…ä¸­æ–‡è·¯å¾„é—®é¢˜
SCRIPT_DIR = Path(__file__).parent.absolute()
TEST_DIR = SCRIPT_DIR / "ç›¸ä¼¼æ–‡ä»¶æµ‹è¯•/txtæµ‹è¯•" # æµ‹è¯•æ–‡ä»¶å¤¹è·¯å¾„
SIMILARITY_THRESHOLD = 0.6  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è®¤ä¸ºæ–‡ä»¶ç›¸ä¼¼ï¼ˆé™ä½é˜ˆå€¼ä»¥ä¾¿åˆ†ææ›´å¤šæ–‡ä»¶ï¼‰
PDF_TEXT_MIN_LENGTH = 80    # åˆ¤æ–­ PDF æ˜¯å¦ä¸ºæ–‡æœ¬å‹çš„æœ€å°å­—ç¬¦æ•°
MAX_PDF_OCR_PAGES = None    # OCR æ—¶æœ€å¤šå¤„ç†çš„é¡µæ•°ï¼ŒNone è¡¨ç¤ºå¤„ç†æ‰€æœ‰é¡µ
IMAGE_EXTENSIONS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}
IMAGE_ANALYSIS_CACHE: Dict[str, Dict[str, Any]] = {}
PHOTO_FEATURE_CACHE: Dict[str, np.ndarray] = {}
PHOTO_PHASH_CACHE: Dict[str, np.ndarray] = {}
PHOTO_HIST_CACHE: Dict[str, np.ndarray] = {}

# ============ å›¾ç‰‡åˆ†ç±»å¸¸é‡ ============
# éç…§ç‰‡ç±»å››åˆ†ç±»ï¼ˆæŒ‰åˆ é™¤å¯èƒ½æ€§ä»é«˜åˆ°ä½ï¼‰
CATEGORY_CN = {
    "temporary": "ä¸´æ—¶ç±»",
    "reference": "å‚è€ƒç±»",
    "saved": "æ”¶è—ç±»",
    "memory": "è®°å¿†ç±»"
}

# åˆ é™¤å¯èƒ½æ€§æƒé‡ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šå®¹æ˜“åˆ é™¤ï¼‰
CATEGORY_DELETE_WEIGHT = {
    "temporary": 0.9,   # 90% åˆ é™¤å€¾å‘
    "reference": 0.6,   # 60% åˆ é™¤å€¾å‘
    "saved": 0.3,       # 30% åˆ é™¤å€¾å‘
    "memory": 0.1       # 10% åˆ é™¤å€¾å‘
}


def compute_photo_feature(path: str) -> np.ndarray:
    """å°†ç…§ç‰‡è½¬æ¢ä¸ºä½ç»´ç‰¹å¾å‘é‡ï¼Œç”¨äºç›¸ä¼¼åº¦æ¯”è¾ƒ"""
    if Image is None:
        return None
    if path in PHOTO_FEATURE_CACHE:
        return PHOTO_FEATURE_CACHE[path]
    try:
        with Image.open(path) as img:
            img = img.convert('RGB').resize((32, 32))
            arr = np.asarray(img, dtype=np.float32).flatten()
            norm = np.linalg.norm(arr)
            if norm > 0:
                arr = arr / norm
            PHOTO_FEATURE_CACHE[path] = arr
            return arr
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆç…§ç‰‡ç‰¹å¾å¤±è´¥ï¼š{path} -> {e}")
        return None


def photo_cosine_similarity(f1: np.ndarray, f2: np.ndarray) -> float:
    if f1 is None or f2 is None:
        return -1.0
    if f1.shape != f2.shape:
        return -1.0
    return float(np.dot(f1, f2) / (np.linalg.norm(f1) * np.linalg.norm(f2) + 1e-10))


def embedding_cosine_similarity(e1: Any, e2: Any) -> float:
    if e1 is None or e2 is None:
        return -1.0
    try:
        a = np.asarray(e1, dtype=float)
        b = np.asarray(e2, dtype=float)
    except Exception:
        return -1.0
    if a.shape != b.shape:
        return -1.0
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10))


def compute_phash_vector(path: str) -> np.ndarray:
    """ç®€å• pHashï¼Œå®ç°ä¸º 8x8 DCT"""
    if Image is None:
        return None
    if path in PHOTO_PHASH_CACHE:
        return PHOTO_PHASH_CACHE[path]
    try:
        with Image.open(path) as img:
            img = img.convert('L').resize((32, 32))
            pixels = np.asarray(img, dtype=np.float32)
            dct = np.fft.fft2(pixels)
            dct_low = np.abs(dct[:8, :8])
            med = np.median(dct_low)
            phash = (dct_low > med).astype(np.uint8).flatten()
            PHOTO_PHASH_CACHE[path] = phash
            return phash
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆ pHash å¤±è´¥ï¼š{path} -> {e}")
        return None


def phash_similarity(a: np.ndarray, b: np.ndarray) -> float:
    if a is None or b is None or a.shape != b.shape:
        return 0.0
    same = np.sum(a == b)
    return same / len(a)


def compute_hsv_hist(path: str, bins: int = 16) -> np.ndarray:
    if Image is None:
        return None
    if path in PHOTO_HIST_CACHE:
        return PHOTO_HIST_CACHE[path]
    try:
        with Image.open(path) as img:
            hsv = img.convert('HSV')
            arr = np.asarray(hsv, dtype=np.float32)
            hist = []
            for channel in range(3):
                h, _ = np.histogram(arr[..., channel], bins=bins, range=(0, 255))
                hist.append(h.astype(np.float32))
            hist = np.concatenate(hist)
            norm = np.linalg.norm(hist)
            if norm > 0:
                hist = hist / norm
            PHOTO_HIST_CACHE[path] = hist
            return hist
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆ HSV ç›´æ–¹å›¾å¤±è´¥ï¼š{path} -> {e}")
        return None


def histogram_similarity(a: np.ndarray, b: np.ndarray) -> float:
    if a is None or b is None or a.shape != b.shape:
        return 0.0
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10))

# Embedding åˆ†å—å¤„ç†é…ç½®
EMBEDDING_MAX_TOKENS = 512       # åµŒå…¥æ¨¡å‹çš„æœ€å¤§ token æ•°ï¼ˆè®¾ç½®ä¸º512 tokensï¼‰
EMBEDDING_CHUNK_SIZE = 1024      # æ¯ä¸ªåˆ†å—çš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆçº¦1024å­—ç¬¦å¯¹åº”512 tokensï¼Œä¸­æ–‡1å­—ç¬¦â‰ˆ1-2 tokensï¼‰
EMBEDDING_CHUNK_OVERLAP = 100    # åˆ†å—é‡å å­—ç¬¦æ•°ï¼Œä¿æŒä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼ˆå‡å°é‡å ä»¥é€‚åº”æ›´å°çš„åˆ†å—ï¼‰

# OCR é…ç½®
OCR_MODEL = "qwen3-vl-plus"      # åœ¨çº¿OCRæ¨¡å‹
PDF_RENDER_SCALE = 300 / 72      # PDF æ¸²æŸ“åˆ†è¾¨ç‡ï¼ˆDPIï¼‰ï¼Œ300ï¼ˆå¹³è¡¡ï¼Œæ¨èï¼‰

# åˆå§‹åŒ– ImageAnalyzer
image_analyzer = None
if ImageAnalyzer:
    try:
        # å¤ç”¨å·²æœ‰çš„å®¢æˆ·ç«¯
        # emb_client (DashScope) æ—¢ç”¨äº embedding ä¹Ÿç”¨äº VL (qwen-vl)
        # chat_client (DeepSeek) ç”¨äºé€»è¾‘åˆ†æ
        image_analyzer = ImageAnalyzer(
            emb_client=emb_client,
            vl_client=emb_client,  # DashScope æ”¯æŒ Qwen-VL
            llm_client=chat_client, # DeepSeek
            vl_model=OCR_MODEL,    # å¤ç”¨é…ç½®çš„æ¨¡å‹å
            debug=True             # å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤º embedding é”™è¯¯
        )
        print("âœ… ImageAnalyzer åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ ImageAnalyzer åˆå§‹åŒ–å¤±è´¥: {e}")

# æ–‡å­—å±‚é¢ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆç”¨äºåˆæ­¥ç­›é€‰ï¼Œé¿å…å¯¹å®Œå…¨ä¸ç›¸ä¼¼çš„æ–‡ä»¶è¿›è¡Œembeddingè®¡ç®—ï¼‰
TEXT_SIMILARITY_THRESHOLD = 0.3  # æ–‡å­—å±‚é¢ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼ç›´æ¥è·³è¿‡embeddingæ¯”è¾ƒ


# ============ PDF / OCR æ”¯æŒ ============
def extract_text_from_pdf(pdf_path: str) -> str:
    """ä¼˜å…ˆä½¿ç”¨ PyPDF2 æå–æ–‡æœ¬å‹ PDF å†…å®¹ï¼ˆå¤„ç†æ‰€æœ‰é¡µé¢ï¼‰"""
    if PdfReader is None:
        print("âš ï¸ æœªå®‰è£… PyPDF2ï¼Œæ— æ³•ç›´æ¥è§£æ PDFã€‚")
        return ""

    try:
        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)
        text_chunks = []
        
        print(f"â„¹ï¸ å¼€å§‹æå– PDF æ–‡æœ¬ï¼ˆå…± {total_pages} é¡µï¼‰ï¼š{Path(pdf_path).name}")
        
        # æ˜¾å¼éå†æ‰€æœ‰é¡µé¢ï¼Œç¡®ä¿å¤„ç†æ‰€æœ‰é¡µé¢
        for page_num in range(total_pages):
            try:
                page = reader.pages[page_num]
                page_text = page.extract_text() or ""
                if page_text:
                    text_chunks.append(page_text)
            except Exception as e:
                print(f"   âš ï¸ æå–ç¬¬ {page_num + 1} é¡µæ–‡æœ¬å¤±è´¥: {e}")
                continue
        
        extracted_pages = len(text_chunks)
        total_chars = sum(len(chunk) for chunk in text_chunks)
        result = "\n".join(text_chunks).strip()
        
        print(f"âœ… PDF æ–‡æœ¬æå–å®Œæˆï¼šå¤„ç†äº† {extracted_pages}/{total_pages} é¡µï¼Œæå– {total_chars} å­—ç¬¦")
        
        return result
    except Exception as e:
        print(f"âš ï¸ è¯»å– PDF æ–‡æœ¬å¤±è´¥ {pdf_path}: {e}")
        import traceback
        print(f"   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return ""


def pil_image_to_base64(pil_img) -> str:
    """
    å°†PIL Imageè½¬æ¢ä¸ºbase64ç¼–ç çš„å›¾ç‰‡URLæ ¼å¼
    
    Args:
        pil_img: PIL Image å¯¹è±¡
    
    Returns:
        base64ç¼–ç çš„å›¾ç‰‡URLå­—ç¬¦ä¸²
    """
    if pil_img is None:
        return ""
    
    try:
        # å°†PIL Imageè½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if pil_img.mode != 'RGB':
            pil_img = pil_img.convert('RGB')
        
        # å°†å›¾ç‰‡ä¿å­˜åˆ°BytesIO
        buffer = BytesIO()
        pil_img.save(buffer, format='JPEG', quality=95)
        buffer.seek(0)
        
        # è½¬æ¢ä¸ºbase64
        image_bytes = buffer.read()
        base64_str = base64.b64encode(image_bytes).decode('utf-8')
        
        # è¿”å›data URLæ ¼å¼
        return f"data:image/jpeg;base64,{base64_str}"
    except Exception as e:
        print(f"âš ï¸ å›¾ç‰‡è½¬æ¢base64å¤±è´¥: {e}")
        return ""


def ocr_image_with_api(pil_img, prompt_text="è¯·è¯†åˆ«å¹¶æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰çš„æ ¼å¼å’Œæ®µè½ç»“æ„ã€‚") -> str:
    """
    ä½¿ç”¨åœ¨çº¿OCR APIï¼ˆqwen3-vl-plusï¼‰è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—
    
    Args:
        pil_img: PIL Image å¯¹è±¡
        prompt_text: OCRæç¤ºè¯ï¼ŒæŒ‡å¯¼æ¨¡å‹å¦‚ä½•è¯†åˆ«æ–‡å­—
    
    Returns:
        è¯†åˆ«å‡ºçš„æ–‡æœ¬å†…å®¹
    """
    if pil_img is None:
        print("âš ï¸ å›¾ç‰‡å¯¹è±¡ä¸ºç©ºï¼Œæ— æ³•æ‰§è¡Œ OCRã€‚")
        return ""
    
    try:
        # å°†PIL Imageè½¬æ¢ä¸ºbase64
        image_url = pil_image_to_base64(pil_img)
        if not image_url:
            print("âš ï¸ å›¾ç‰‡è½¬æ¢å¤±è´¥ï¼Œæ— æ³•æ‰§è¡Œ OCRã€‚")
            return ""
        
        # è°ƒç”¨åœ¨çº¿OCR API
        completion = emb_client.chat.completions.create(
            model=OCR_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": image_url
                            },
                        },
                        {"type": "text", "text": prompt_text},
                    ],
                },
            ],
            stream=False,
        )
        
        # æå–è¯†åˆ«ç»“æœ
        raw_text = completion.choices[0].message.content.strip()
        return raw_text
        
    except Exception as e:
        print(f"âš ï¸ åœ¨çº¿OCRè¯†åˆ«å¤±è´¥: {e}")
        import traceback
        print(f"   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return ""


def extract_text_from_pdf_via_ocr(pdf_path: str) -> str:
    """ä½¿ç”¨ pypdfium2 å°† PDF æ¸²æŸ“ä¸ºå›¾ç‰‡åè¿›è¡Œ OCR"""
    if pdfium is None:
        print("âš ï¸ æœªå®‰è£… pypdfium2ï¼Œæ— æ³•å¯¹å›¾ç‰‡å‹ PDF æ‰§è¡Œ OCRã€‚")
        return ""

    try:
        pdf = pdfium.PdfDocument(pdf_path)
    except Exception as e:
        print(f"âš ï¸ æ‰“å¼€ PDF å¤±è´¥ {pdf_path}: {e}")
        return ""

    text_parts = []
    try:
        total_pages = len(pdf)
        # ç¡®å®šè¦å¤„ç†çš„é¡µæ•°
        pages_to_process = total_pages if MAX_PDF_OCR_PAGES is None else min(total_pages, MAX_PDF_OCR_PAGES)
        
        # è¾“å‡ºOCRå¤„ç†å¼€å§‹ä¿¡æ¯
        if MAX_PDF_OCR_PAGES is not None and total_pages > MAX_PDF_OCR_PAGES:
            print(f"â„¹ï¸ ä½¿ç”¨ {OCR_MODEL} æ¨¡å‹è¿›è¡Œ OCR å¤„ç†ï¼ˆå…± {total_pages} é¡µï¼Œå°†å¤„ç†å‰ {MAX_PDF_OCR_PAGES} é¡µï¼‰ï¼š{Path(pdf_path).name}")
        else:
            print(f"â„¹ï¸ ä½¿ç”¨ {OCR_MODEL} æ¨¡å‹è¿›è¡Œ OCR å¤„ç†ï¼ˆå…± {total_pages} é¡µï¼‰ï¼š{Path(pdf_path).name}")
        
        for index in range(pages_to_process):
            try:
                # å°è¯•ä¸åŒçš„é¡µé¢è®¿é—®æ–¹å¼
                try:
                    page = pdf[index]  # æ–°ç‰ˆæœ¬ API
                except (TypeError, AttributeError):
                    page = pdf.get_page(index)  # æ—§ç‰ˆæœ¬ API
                
                # å°è¯•ä¸åŒçš„æ¸²æŸ“æ–¹æ³•
                pil_image = None
                try:
                    # æ–¹æ³•1: render() æ–¹æ³•è¿”å› PdfBitmapï¼Œéœ€è¦è½¬æ¢ä¸º PIL Image
                    # ä½¿ç”¨æ›´é«˜çš„åˆ†è¾¨ç‡æé«˜ OCR è´¨é‡
                    bitmap = page.render(scale=PDF_RENDER_SCALE)
                    if bitmap:
                        # æ£€æŸ¥ bitmap ç±»å‹å¹¶è½¬æ¢
                        if hasattr(bitmap, 'to_pil'):
                            # pypdfium2 æ–°ç‰ˆæœ¬ï¼šä½¿ç”¨ to_pil() æ–¹æ³•
                            pil_image = bitmap.to_pil()
                        elif hasattr(bitmap, 'asarray'):
                            # é€šè¿‡ numpy æ•°ç»„è½¬æ¢
                            import numpy as np
                            array = bitmap.asarray()
                            if Image:
                                pil_image = Image.fromarray(array)
                        elif hasattr(bitmap, 'convert'):
                            # å¦‚æœå·²ç»æ˜¯ PIL Imageï¼ˆæŸäº›ç‰ˆæœ¬ï¼‰
                            pil_image = bitmap
                        else:
                            # å°è¯•å…¶ä»–å¯èƒ½çš„è½¬æ¢æ–¹æ³•
                            try:
                                # æŸäº›ç‰ˆæœ¬å¯èƒ½æ”¯æŒç›´æ¥è½¬æ¢
                                if Image:
                                    pil_image = Image.fromarray(np.array(bitmap))
                            except:
                                pass
                except Exception as render_error:
                    try:
                        # æ–¹æ³•2: render_topil() æ–¹æ³•ï¼ˆæŸäº›ç‰ˆæœ¬ç›´æ¥è¿”å› PIL Imageï¼‰
                        pil_image = page.render_topil(scale=PDF_RENDER_SCALE)
                    except AttributeError:
                        try:
                            # æ–¹æ³•3: render_to() æ–¹æ³•
                            from io import BytesIO
                            buffer = BytesIO()
                            page.render_to(buffer, scale=PDF_RENDER_SCALE)
                            buffer.seek(0)
                            if Image:
                                pil_image = Image.open(buffer)
                        except Exception as e:
                            print(f"   âš ï¸ æ¸²æŸ“æ–¹æ³•å¤±è´¥: {render_error}, å¤‡é€‰æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
                            pass
                
                if pil_image:
                    # ä½¿ç”¨åœ¨çº¿OCR APIè¯†åˆ«é¡µé¢æ–‡å­—
                    page_text = ocr_image_with_api(
                        pil_image, 
                        prompt_text="è¯·è¯†åˆ«å¹¶æå–PDFé¡µé¢ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰çš„æ ¼å¼ã€æ®µè½ç»“æ„å’Œæ’ç‰ˆã€‚å¦‚æœæ˜¯è¡¨æ ¼ï¼Œè¯·ä»¥Markdownè¡¨æ ¼æ ¼å¼è¾“å‡ºã€‚"
                    )
                    
                    if page_text:
                        text_parts.append(f"ã€ç¬¬ {index + 1} é¡µã€‘\n{page_text}")
                else:
                    print(f"   âš ï¸ ç¬¬ {index + 1} é¡µæ¸²æŸ“å¤±è´¥ï¼Œæ— æ³•è·å–å›¾ç‰‡å¯¹è±¡")
                
                # å°è¯•å…³é—­é¡µé¢
                try:
                    page.close()
                except:
                    pass
                    
            except Exception as e:
                print(f"âš ï¸ å¤„ç†ç¬¬ {index + 1}/{pages_to_process} é¡µæ—¶å‡ºé”™: {e}")
                continue
            
            # æ˜¾ç¤ºè¿›åº¦
            if (index + 1) % 10 == 0 or (index + 1) == pages_to_process:
                print(f"   ğŸ“„ å·²å¤„ç† {index + 1}/{pages_to_process} é¡µ...")
        
        # è®¡ç®—æå–çš„å­—ç¬¦æ•°
        total_chars = sum(len(t) for t in text_parts)
        extracted_pages = len(text_parts)
        
        print(f"âœ… ä½¿ç”¨ {OCR_MODEL} æ¨¡å‹ OCR å¤„ç†å®Œæˆï¼šå¤„ç†äº† {extracted_pages}/{pages_to_process} é¡µï¼Œæå– {total_chars} å­—ç¬¦")
        return "\n\n".join(text_parts).strip()
    finally:
        try:
            pdf.close()
        except:
            pass


def extract_text_from_image(image_path: str) -> str:
    """å¯¹å•å¼ å›¾ç‰‡æ‰§è¡Œ OCRï¼ˆä½¿ç”¨åœ¨çº¿OCR APIï¼‰"""
    if Image is None:
        print("âš ï¸ æœªå®‰è£… Pillowï¼Œæ— æ³•è¯»å–å›¾ç‰‡ã€‚")
        return ""

    try:
        print(f"â„¹ï¸ ä½¿ç”¨ {OCR_MODEL} æ¨¡å‹è¿›è¡Œ OCR å¤„ç†ï¼š{Path(image_path).name}")
        with Image.open(image_path) as pil_img:
            ocr_text = ocr_image_with_api(
                pil_img,
                prompt_text="è¯·è¯†åˆ«å¹¶æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰çš„æ ¼å¼å’Œæ®µè½ç»“æ„ã€‚å¦‚æœæ˜¯è¡¨æ ¼ï¼Œè¯·ä»¥Markdownè¡¨æ ¼æ ¼å¼è¾“å‡ºã€‚"
            )
            if ocr_text:
                print(f"âœ… ä½¿ç”¨ {OCR_MODEL} æ¨¡å‹ OCR å¤„ç†å®Œæˆï¼šæå– {len(ocr_text)} å­—ç¬¦")
            return ocr_text
    except Exception as e:
        print(f"âš ï¸ æ‰“å¼€å›¾ç‰‡å¤±è´¥ {image_path}: {e}")
        return ""

# ============ å·¥å…·å‡½æ•°éƒ¨åˆ† ============
def split_text_into_chunks(text: str, chunk_size: int = None, overlap: int = None) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªå—ï¼Œç”¨äºåˆ†æ‰¹å¤„ç† embedding
    
    Args:
        text: è¦åˆ†å‰²çš„æ–‡æœ¬
        chunk_size: æ¯ä¸ªåˆ†å—çš„æœ€å¤§å­—ç¬¦æ•°ï¼ŒNone æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
        overlap: åˆ†å—é‡å å­—ç¬¦æ•°ï¼ŒNone æ—¶ä½¿ç”¨é»˜è®¤é…ç½®
    
    Returns:
        æ–‡æœ¬å—åˆ—è¡¨
    """
    if not text:
        return []
    
    chunk_size = chunk_size or EMBEDDING_CHUNK_SIZE
    overlap = overlap or EMBEDDING_CHUNK_OVERLAP
    
    # å¦‚æœæ–‡æœ¬é•¿åº¦å°äºåˆ†å—å¤§å°ï¼Œç›´æ¥è¿”å›
    if len(text) <= chunk_size:
        return [text]
    
    chunks = []
    start = 0
    
    while start < len(text):
        # è®¡ç®—å½“å‰å—çš„ç»“æŸä½ç½®
        end = start + chunk_size
        
        # å¦‚æœè¿˜æ²¡åˆ°æ–‡æœ¬æœ«å°¾ï¼Œå°è¯•åœ¨åˆé€‚çš„ä½ç½®æ–­å¼€ï¼ˆä¼˜å…ˆåœ¨æ¢è¡Œç¬¦æˆ–å¥å·å¤„ï¼‰
        if end < len(text):
            # å‘å‰æŸ¥æ‰¾æ¢è¡Œç¬¦æˆ–å¥å·
            break_pos = end
            for i in range(end, max(start + chunk_size - 500, start), -1):
                if text[i] in ['\n', 'ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?']:
                    break_pos = i + 1
                    break
            
            # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„æ–­ç‚¹ï¼Œä½¿ç”¨åŸä½ç½®
            if break_pos == end:
                # å°è¯•åœ¨ç©ºæ ¼å¤„æ–­å¼€
                for i in range(end, max(start + chunk_size - 200, start), -1):
                    if text[i] in [' ', '\t']:
                        break_pos = i + 1
                        break
            
            end = break_pos
        
        # æå–å½“å‰å—
        chunk = text[start:end]
        chunks.append(chunk)
        
        # è®¡ç®—ä¸‹ä¸€ä¸ªå—çš„èµ·å§‹ä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
        start = end - overlap
        if start >= len(text):
            break
    
    return chunks


def get_embedding(text: str, use_chunking: bool = True) -> List[float]:
    """
    è°ƒç”¨é€šä¹‰åƒé—®æ–‡æœ¬åµŒå…¥ APIï¼Œæ”¯æŒé•¿æ–‡æœ¬åˆ†å—å¤„ç†
    
    Args:
        text: è¦åµŒå…¥çš„æ–‡æœ¬
        use_chunking: æ˜¯å¦å¯¹é•¿æ–‡æœ¬è¿›è¡Œåˆ†å—å¤„ç†
    
    Returns:
        åµŒå…¥å‘é‡ï¼ˆå•ä¸ªå‘é‡æˆ–å¹³å‡å‘é‡ï¼‰
    """
    if not text:
        return None
    
    try:
        # å¦‚æœæ–‡æœ¬è¾ƒçŸ­æˆ–ä¸éœ€è¦åˆ†å—ï¼Œç›´æ¥å¤„ç†
        if not use_chunking or len(text) <= EMBEDDING_CHUNK_SIZE:
            response = emb_client.embeddings.create(model=EMBED_MODEL, input=text)
            return response.data[0].embedding
        
        # é•¿æ–‡æœ¬éœ€è¦åˆ†å—å¤„ç†
        chunks = split_text_into_chunks(text)
        
        if len(chunks) == 1:
            # åªæœ‰ä¸€ä¸ªå—ï¼Œç›´æ¥å¤„ç†
            response = emb_client.embeddings.create(model=EMBED_MODEL, input=chunks[0])
            return response.data[0].embedding
        
        # å¤šä¸ªå—ï¼Œåˆ†åˆ«è·å– embedding ç„¶ååŠ æƒå¹³å‡
        total_chars_in_chunks = sum(len(chunk) for chunk in chunks)
        print(f"   ğŸ“¦ æ–‡æœ¬è¾ƒé•¿ï¼ˆ{len(text)} å­—ç¬¦ï¼‰ï¼Œåˆ† {len(chunks)} å—å¤„ç†ï¼ˆæ€»å­—ç¬¦æ•°éªŒè¯: {total_chars_in_chunks} å­—ç¬¦ï¼‰...")
        
        # éªŒè¯åˆ†å—å®Œæ•´æ€§
        if abs(total_chars_in_chunks - len(text)) > len(text) * 0.05:  # å…è®¸5%çš„è¯¯å·®ï¼ˆç”±äºé‡å ï¼‰
            print(f"   âš ï¸ è­¦å‘Šï¼šåˆ†å—å­—ç¬¦æ€»æ•° ({total_chars_in_chunks}) ä¸åŸæ–‡ ({len(text)}) å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨æ–‡æœ¬ä¸¢å¤±")
        
        embeddings = []
        chunk_weights = []  # å­˜å‚¨æ¯ä¸ªå—çš„æƒé‡ï¼ˆæŒ‰å­—ç¬¦æ•°ï¼‰
        
        for i, chunk in enumerate(chunks, 1):
            try:
                response = emb_client.embeddings.create(model=EMBED_MODEL, input=chunk)
                embedding = response.data[0].embedding
                embeddings.append(embedding)
                chunk_weights.append(len(chunk))  # ä½¿ç”¨å­—ç¬¦æ•°ä½œä¸ºæƒé‡
                
                # æ˜¾ç¤ºè¿›åº¦
                if len(chunks) > 5 and i % 5 == 0:
                    print(f"     å·²å¤„ç† {i}/{len(chunks)} å—ï¼ˆå½“å‰å— {len(chunk)} å­—ç¬¦ï¼‰...")
                    
            except Exception as e:
                print(f"   âš ï¸ ç¬¬ {i} å— embedding å¤±è´¥: {e}ï¼Œè¯¥å—å­—ç¬¦æ•°: {len(chunk)}")
                continue
        
        if not embeddings:
            print(f"   âŒ æ‰€æœ‰åˆ†å—çš„ embedding éƒ½å¤±è´¥äº†")
            return None
        
        # éªŒè¯å¤„ç†çš„å—æ•°
        if len(embeddings) < len(chunks):
            print(f"   âš ï¸ è­¦å‘Šï¼šåªæˆåŠŸå¤„ç†äº† {len(embeddings)}/{len(chunks)} ä¸ªåˆ†å—ï¼Œéƒ¨åˆ†æ–‡æœ¬å¯èƒ½æœªå‚ä¸embeddingè®¡ç®—")
        
        # è®¡ç®—åŠ æƒå¹³å‡ embeddingï¼ˆæŒ‰å—é•¿åº¦åŠ æƒï¼Œç¡®ä¿é•¿å—æœ‰æ›´å¤§æƒé‡ï¼‰
        if len(embeddings) == 1:
            return embeddings[0]
        
        # è½¬æ¢ä¸º numpy æ•°ç»„è¿›è¡ŒåŠ æƒå¹³å‡
        embeddings_array = np.array(embeddings)
        weights_array = np.array(chunk_weights)
        # å½’ä¸€åŒ–æƒé‡
        weights_array = weights_array / weights_array.sum()
        # åŠ æƒå¹³å‡
        avg_embedding = np.average(embeddings_array, axis=0, weights=weights_array).tolist()
        
        processed_chars = sum(chunk_weights)
        print(f"   âœ… æˆåŠŸåˆå¹¶ {len(embeddings)} ä¸ªåˆ†å—çš„ embeddingï¼ˆåŠ æƒå¹³å‡ï¼Œå¤„ç†äº† {processed_chars}/{len(text)} å­—ç¬¦ï¼‰")
        return avg_embedding
        
    except Exception as e:
        err_msg = str(e)
        print(f"âŒ è·å–åµŒå…¥å¤±è´¥ï¼ˆ{EMBED_MODEL}ï¼‰: {err_msg}")
        return None


def text_similarity(text1: str, text2: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬åœ¨æ–‡å­—å±‚é¢çš„ç›¸ä¼¼åº¦ï¼ˆç”¨äºåˆæ­¥ç­›é€‰ï¼‰
    
    ä½¿ç”¨å¤šç§æ–¹æ³•ç»„åˆï¼š
    1. Jaccardç›¸ä¼¼åº¦ï¼ˆåŸºäºå­—ç¬¦é›†åˆï¼‰
    2. å­—ç¬¦é‡å æ¯”ä¾‹
    3. é•¿åº¦ç›¸ä¼¼åº¦
    
    Args:
        text1: ç¬¬ä¸€ä¸ªæ–‡æœ¬
        text2: ç¬¬äºŒä¸ªæ–‡æœ¬
    
    Returns:
        ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ä¹‹é—´ï¼‰
    """
    if not text1 or not text2:
        return 0.0
    
    # æ–¹æ³•1: Jaccardç›¸ä¼¼åº¦ï¼ˆåŸºäºå­—ç¬¦é›†åˆï¼‰
    set1 = set(text1)
    set2 = set(text2)
    if len(set1) == 0 and len(set2) == 0:
        jaccard = 1.0
    elif len(set1) == 0 or len(set2) == 0:
        jaccard = 0.0
    else:
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        jaccard = intersection / union if union > 0 else 0.0
    
    # æ–¹æ³•2: å­—ç¬¦é‡å æ¯”ä¾‹ï¼ˆè€ƒè™‘å­—ç¬¦é¢‘ç‡ï¼‰
    # è®¡ç®—å…¬å…±å­—ç¬¦çš„æ€»æ•°ï¼ˆè€ƒè™‘é‡å¤ï¼‰
    common_chars = 0
    text1_chars = {}
    text2_chars = {}
    
    for char in text1:
        text1_chars[char] = text1_chars.get(char, 0) + 1
    for char in text2:
        text2_chars[char] = text2_chars.get(char, 0) + 1
    
    for char in set(text1) & set(text2):
        common_chars += min(text1_chars[char], text2_chars[char])
    
    total_chars = len(text1) + len(text2)
    overlap_ratio = (2 * common_chars) / total_chars if total_chars > 0 else 0.0
    
    # æ–¹æ³•3: é•¿åº¦ç›¸ä¼¼åº¦
    len1, len2 = len(text1), len(text2)
    if len1 == 0 and len2 == 0:
        len_sim = 1.0
    elif len1 == 0 or len2 == 0:
        len_sim = 0.0
    else:
        len_sim = min(len1, len2) / max(len1, len2)
    
    # ç»¼åˆç›¸ä¼¼åº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
    # Jaccardæƒé‡0.4ï¼Œé‡å æ¯”ä¾‹æƒé‡0.4ï¼Œé•¿åº¦ç›¸ä¼¼åº¦æƒé‡0.2
    similarity = 0.4 * jaccard + 0.4 * overlap_ratio + 0.2 * len_sim
    
    return similarity


def cosine_similarity(a: List[float], b: List[float]) -> float:
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    if a is None or b is None:
        return -1.0
    a, b = np.array(a), np.array(b)
    if a.shape != b.shape:
        return -1.0
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-10)


def read_file_content(file_path: str) -> str:
    """
    è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒ txtã€mdã€docxã€pdfã€å›¾ç‰‡ç­‰æ–‡ä»¶ã€‚
    å¯¹äºä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œå°†è¿”å›ç©ºå­—ç¬¦ä¸²å¹¶æ‰“å°æç¤ºã€‚
    """
    ext = Path(file_path).suffix.lower()
    try:
        if ext == ".txt" or ext == ".md":
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        elif ext == ".docx":
            doc = Document(file_path)
            return "\n".join([p.text for p in doc.paragraphs])
        elif ext == ".pdf":
            # å…ˆå°è¯•ç›´æ¥æå–æ–‡æœ¬
            text_content = extract_text_from_pdf(file_path)
            if len(text_content) >= PDF_TEXT_MIN_LENGTH:
                print(f"âœ… PDF æ–‡æœ¬æå–æˆåŠŸï¼ˆ{len(text_content)} å­—ç¬¦ï¼‰ï¼š{Path(file_path).name}")
                return text_content

            # å¦‚æœæ–‡æœ¬æå–å¤±è´¥æˆ–å†…å®¹å¤ªå°‘ï¼Œå°è¯• OCR
            print(f"â„¹ï¸ PDF æ–‡æœ¬æå–å†…å®¹è¾ƒå°‘ï¼ˆ{len(text_content)} å­—ç¬¦ï¼‰ï¼Œå°è¯• OCRï¼š{Path(file_path).name}")
            ocr_content = extract_text_from_pdf_via_ocr(file_path)
            if ocr_content:
                print(f"âœ… PDF OCR æˆåŠŸï¼ˆ{len(ocr_content)} å­—ç¬¦ï¼‰ï¼š{Path(file_path).name}")
                return ocr_content

            # å¦‚æœ OCR ä¹Ÿå¤±è´¥ï¼Œè¿”å›åŸå§‹æå–ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
            if text_content:
                print(f"âš ï¸ PDF OCR å¤±è´¥ï¼Œè¿”å›åŸå§‹æå–ç»“æœï¼ˆ{len(text_content)} å­—ç¬¦ï¼‰ï¼š{Path(file_path).name}")
                return text_content
            else:
                print(f"âŒ æ— æ³•ä» PDF æå–æ–‡æœ¬ï¼ˆæ–‡æœ¬æå–å’Œ OCR å‡å¤±è´¥ï¼‰ï¼š{Path(file_path).name}")
                return ""
        elif ext in IMAGE_EXTENSIONS:
            if image_analyzer is None:
                print(f"âš ï¸ æœªåˆå§‹åŒ– ImageAnalyzerï¼Œè·³è¿‡å›¾ç‰‡è§†è§‰ç†è§£ï¼š{file_path}")
                return ""
            # å¯¹äºå›¾ç‰‡ï¼Œè¿”å›æ›´è¯¦ç»†çš„æè¿°ç”¨äº embedding
            analysis = get_or_run_image_analysis(file_path)
            if analysis:
                # æ„å»ºæ›´ä¸°å¯Œçš„æ–‡æœ¬æè¿°
                parts = []
                # 1. çŸ­æè¿°ï¼ˆæœ€é‡è¦ï¼‰
                if analysis.get('short_description'):
                    parts.append(analysis['short_description'])
                # 2. åœºæ™¯æè¿°
                vl = analysis.get('vl', {})
                if vl.get('scene'):
                    parts.append(vl['scene'])
                # 3. äººè„¸ä¿¡æ¯
                if vl.get('faces') and vl['faces'] > 0:
                    parts.append(f"{vl['faces']} people in image")
                    if vl.get('eyes_open') is not None:
                        parts.append("eyes open" if vl['eyes_open'] else "eyes closed")
                # 4. å›¾ç‰‡ç±»å‹ï¼ˆphoto å¾ˆé‡è¦ï¼‰
                if vl.get('type'):
                    parts.append(f"type: {vl['type']}")
                
                return " | ".join(parts) if parts else Path(file_path).stem
            print(f"âš ï¸ å›¾ç‰‡è§†è§‰ç†è§£å¤±è´¥ï¼š{file_path}")
            return ""
        else:
            print(f"âš ï¸ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{ext}")
            return ""
    except Exception as e:
        print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return ""


def scan_files(directory) -> List[Dict]:
    """æ‰«æç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨"""
    file_infos = []
    directory_path = Path(directory) if isinstance(directory, (str, Path)) else directory
    
    if not directory_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
        return file_infos
    
    # æ’åºæ–‡ä»¶åˆ—è¡¨ä»¥ç¡®ä¿è·¨å¹³å°ä¸€è‡´æ€§
    for file_path in sorted(directory_path.iterdir(), key=lambda p: p.name.lower()):
        if file_path.is_file():
            file_info = {
                "path": str(file_path),
                "name": file_path.name,
                "content": read_file_content(str(file_path))
            }
            
            # å¯¹äºå›¾ç‰‡ï¼Œç›´æ¥é™„åŠ  embeddingï¼ˆImageAnalyzer å·²ç»ç”Ÿæˆäº†ï¼‰
            ext = file_path.suffix.lower()
            if ext in IMAGE_EXTENSIONS and image_analyzer is not None:
                analysis = get_or_run_image_analysis(str(file_path))
                if analysis and analysis.get('embedding'):
                    file_info['embedding'] = analysis['embedding']
            
            file_infos.append(file_info)
    
    return file_infos


def find_similar_file_pairs(file_infos: List[Dict], similarity_threshold: float = 0.7) -> List[Tuple[Dict, Dict, float]]:
    """
    æ‰¾åˆ°ç›¸ä¼¼çš„æ–‡ä»¶å¯¹
    
    æµç¨‹ï¼š
    1. å…ˆè¿›è¡Œæ–‡å­—å±‚é¢çš„ç›¸ä¼¼åº¦æ¯”è¾ƒï¼ˆå¿«é€Ÿç­›é€‰ï¼‰
    2. å¯¹æ–‡å­—å±‚é¢ç›¸ä¼¼çš„æ–‡ä»¶è¿›è¡Œembeddingè®¡ç®—
    3. ä½¿ç”¨embeddingè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æ¯”è¾ƒ
    """
    # è¿‡æ»¤æ‰æ²¡æœ‰å†…å®¹çš„æ–‡ä»¶
    valid_files = [f for f in file_infos if f.get("content")]
    
    if len(valid_files) < 2:
        print("âŒ æœ‰æ•ˆæ–‡ä»¶æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒ")
        return []
    
    print(f"\nğŸ“ ç¬¬ä¸€æ­¥ï¼šæ–‡å­—å±‚é¢ç›¸ä¼¼åº¦æ¯”è¾ƒï¼ˆç­›é€‰å€™é€‰æ–‡ä»¶å¯¹ï¼‰...")
    text_similar_pairs = []
    text_similarities = []
    
    # å…ˆè¿›è¡Œæ–‡å­—å±‚é¢çš„ç›¸ä¼¼åº¦æ¯”è¾ƒ
    for file1, file2 in tqdm(combinations(valid_files, 2), desc="æ–‡å­—å±‚é¢æ¯”è¾ƒ", total=len(valid_files)*(len(valid_files)-1)//2):
        text_sim = text_similarity(file1["content"], file2["content"])
        text_similarities.append((file1["name"], file2["name"], text_sim))
        
        # åªä¿ç•™æ–‡å­—å±‚é¢ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼çš„æ–‡ä»¶å¯¹
        if text_sim >= TEXT_SIMILARITY_THRESHOLD:
            text_similar_pairs.append((file1, file2, text_sim))
    
    print(f"   âœ… æ–‡å­—å±‚é¢æ¯”è¾ƒå®Œæˆï¼Œæ‰¾åˆ° {len(text_similar_pairs)} å¯¹å€™é€‰æ–‡ä»¶ï¼ˆæ–‡å­—ç›¸ä¼¼åº¦ >= {TEXT_SIMILARITY_THRESHOLD}ï¼‰")
    
    if len(text_similar_pairs) == 0:
        print(f"\nâœ… æœªæ‰¾åˆ°æ–‡å­—å±‚é¢ç›¸ä¼¼çš„æ–‡ä»¶å¯¹ï¼ˆæ–‡å­—ç›¸ä¼¼åº¦é˜ˆå€¼: {TEXT_SIMILARITY_THRESHOLD}ï¼‰")
        return []
    
    # æ”¶é›†éœ€è¦è®¡ç®—embeddingçš„æ–‡ä»¶ï¼ˆå»é‡ï¼‰
    unique_files = {}
    for file1, file2, _ in text_similar_pairs:
        unique_files[id(file1)] = file1
        unique_files[id(file2)] = file2
    
    # ä¸ºå€™é€‰æ–‡ä»¶ç”ŸæˆåµŒå…¥å‘é‡
    print(f"\nğŸ” ç¬¬äºŒæ­¥ï¼šä¸º {len(unique_files)} ä¸ªå€™é€‰æ–‡ä»¶ç”ŸæˆåµŒå…¥å‘é‡...")
    
    for file_id, file_info in tqdm(unique_files.items(), desc="ç”ŸæˆåµŒå…¥å‘é‡"):
        if file_info.get("embedding") is None:
            file_info["embedding"] = get_embedding(file_info["content"])
    
    # è¿‡æ»¤æ‰embeddingå¤±è´¥çš„æ–‡ä»¶å¯¹
    valid_pairs = []
    for file1, file2, text_sim in text_similar_pairs:
        if file1.get("embedding") is not None and file2.get("embedding") is not None:
            valid_pairs.append((file1, file2, text_sim))
    
    if len(valid_pairs) == 0:
        print("âŒ æ‰€æœ‰å€™é€‰æ–‡ä»¶å¯¹çš„embeddingç”Ÿæˆéƒ½å¤±è´¥äº†")
        return []
    
    print(f"\nğŸ§® ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨embeddingè¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æ¯”è¾ƒ...")
    similar_pairs = []
    all_similarities = []
    
    # ä½¿ç”¨embeddingè®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
    for file1, file2, text_sim in tqdm(valid_pairs, desc="è¯­ä¹‰ç›¸ä¼¼åº¦æ¯”è¾ƒ"):
        semantic_sim = cosine_similarity(file1["embedding"], file2["embedding"])
        all_similarities.append((file1["name"], file2["name"], text_sim, semantic_sim))
        
        if semantic_sim >= similarity_threshold:
            similar_pairs.append((file1, file2, semantic_sim))
    
    # è¾“å‡ºæ‰€æœ‰æ–‡ä»¶å¯¹çš„ç›¸ä¼¼åº¦ï¼ˆæ–‡å­—å±‚é¢ + è¯­ä¹‰å±‚é¢ï¼‰
    print(f"\nğŸ“Š æ‰€æœ‰æ–‡ä»¶å¯¹çš„ç›¸ä¼¼åº¦ï¼ˆæ–‡å­—å±‚é¢ | è¯­ä¹‰å±‚é¢ï¼‰ï¼š")
    for name1, name2, text_sim, sem_sim in sorted(all_similarities, key=lambda x: x[3], reverse=True):
        print(f"   {name1} <-> {name2}: æ–‡å­—={text_sim:.3f} | è¯­ä¹‰={sem_sim:.3f}")
    
    # æŒ‰è¯­ä¹‰ç›¸ä¼¼åº¦é™åºæ’åº
    similar_pairs.sort(key=lambda x: x[2], reverse=True)
    
    return similar_pairs


def analyze_and_report_images(file_infos: List[Dict], output_dir: Path):
    """
    å¯¹æ‰«æåˆ°çš„å›¾ç‰‡è¿›è¡Œæ·±åº¦åˆ†æï¼ˆBestShotã€å†…å®¹ç†è§£ã€åˆ é™¤/ä¿ç•™å»ºè®®ï¼‰
    å¹¶å°†ç»“æœè¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶
    """
    if image_analyzer is None:
        return

    images = [f for f in file_infos if Path(f['path']).suffix.lower() in IMAGE_EXTENSIONS]
    if not images:
        return

    print(f"\nğŸ–¼ï¸ æ­£åœ¨å¯¹ {len(images)} å¼ å›¾ç‰‡è¿›è¡Œæ·±åº¦åˆ†æä¸å»é‡å»ºè®®...")
    
    analysis_results = []
    
    # å‡†å¤‡è¯¦ç»†æ—¥å¿—æ–‡ä»¶
    log_file = output_dir / "image_analysis_details.txt"
    
    # æ”¶é›†åˆ†æç»“æœåå†ç»Ÿä¸€è¾“å‡ºï¼Œä¾¿äºæ‰§è¡Œç›¸ä¼¼ç…§ç‰‡å»é‡
    for img_info in tqdm(images, desc="å›¾ç‰‡åˆ†æ"):
        path = img_info['path']
        name = img_info['name']
        
        try:
            # åŸºç¡€åˆ†æï¼ˆVLæ¨¡å‹ï¼‰
            res = get_or_run_image_analysis(path)
            if not res:
                raise RuntimeError("æ— æ³•è·å–å›¾ç‰‡åˆ†æç»“æœ")
            
            # åˆ¤æ–­ï¼šçœŸå®ç…§ç‰‡ or éç…§ç‰‡ç±»
            is_real_photo = not res.get('likely_screenshot', False)
            
            if is_real_photo:
                # çœŸå®ç…§ç‰‡ â†’ æå–ç‰¹å¾ç”¨äº BestShot å»é‡
                res['photo_feature'] = compute_photo_feature(path)
            else:
                # éç…§ç‰‡ç±» â†’ LLM å››åˆ†ç±»
                llm_result = image_analyzer.screenshot_classify_with_llm(res)
                res['category'] = llm_result.get('category', 'saved')
                res['app_name'] = llm_result.get('app_name', '')
                
                category_cn = CATEGORY_CN.get(res['category'], 'æœªçŸ¥')
                suggestion_text = llm_result.get('suggestion', 'keep')
                print(f"      ğŸ·ï¸ åˆ†ç±»: {category_cn} | å»ºè®®: {suggestion_text}")
                
                # LLM å»ºè®®åˆ é™¤ â†’ æ ‡è®°
                if llm_result.get('suggestion') == 'delete':
                    res.setdefault('suggestion', {})
                    res['suggestion']['delete'] = True
                    res['suggestion']['reason'] = f'LLMå»ºè®®åˆ é™¤ï¼ˆ{category_cn}ï¼‰'
            
            # åŒæ­¥ embedding åˆ° img_infoï¼ˆç”¨äºç›¸ä¼¼åº¦æ¯”è¾ƒï¼‰
            if res.get('embedding'):
                img_info['embedding'] = res['embedding']
            
            analysis_results.append(res)

        except Exception as e:
            print(f"âŒ åˆ†æå›¾ç‰‡ {name} å¤±è´¥: {e}")
    
    # åˆ†ç±»ï¼šçœŸå®ç…§ç‰‡ vs éç…§ç‰‡ç±»
    real_photos = [r for r in analysis_results if not r.get('likely_screenshot')]
    non_photos = [r for r in analysis_results if r.get('likely_screenshot')]
    
    # ç»Ÿè®¡éç…§ç‰‡ç±»çš„åˆ†å¸ƒ
    category_count = {'temporary': 0, 'reference': 0, 'saved': 0, 'memory': 0}
    for r in non_photos:
        cat = r.get('category', 'saved')
        category_count[cat] = category_count.get(cat, 0) + 1
    
    print(f"\nğŸ“Š å›¾ç‰‡åˆ†ç±»ç»Ÿè®¡ï¼š")
    print(f"   ğŸ“¸ çœŸå®ç…§ç‰‡: {len(real_photos)} å¼ ï¼ˆBestShot å»é‡ï¼‰")
    print(f"\n   éç…§ç‰‡ç±»ï¼š")
    print(f"      ğŸ—‘ï¸ ä¸´æ—¶ç±»: {category_count['temporary']} å¼ ï¼ˆåˆ é™¤å¯èƒ½æ€§æœ€é«˜ï¼‰")
    print(f"      ğŸ“‹ å‚è€ƒç±»: {category_count['reference']} å¼ ï¼ˆåˆ é™¤å¯èƒ½æ€§ä¸­é«˜ï¼‰")
    print(f"      ğŸ’¾ æ”¶è—ç±»: {category_count['saved']} å¼ ï¼ˆåˆ é™¤å¯èƒ½æ€§ä¸­ä½ï¼‰")
    print(f"      â“ è®°å¿†ç±»: {category_count['memory']} å¼ ï¼ˆæ‰«æä»¶ç­‰ï¼‰")
    
    # å»é‡
    mark_similar_photos(real_photos)
    mark_similar_screenshots(non_photos)
    
    print(f"\n{'='*60}")
    print(f"{'å›¾ç‰‡æ–‡ä»¶':<20} | {'ç±»å‹':<12} | {'æ ‡ç­¾/æè¿°':<18} | {'å¤„ç†å»ºè®®'}")
    print(f"{'-'*60}")
    for res in analysis_results:
        name = Path(res['path']).name
        # æ˜¾ç¤ºç±»å‹
        if not res.get('likely_screenshot'):
            img_type = "ğŸ“¸ ç…§ç‰‡"
        else:
            img_type = CATEGORY_CN.get(res.get('category', 'saved'), 'æ”¶è—ç±»')
        
        # æè¿°ä¿¡æ¯
        desc = res.get('short_description', '') or res.get('vl', {}).get('scene', '')
        if desc and len(desc) > 18:
            desc = desc[:15] + "..."
        
        suggestion = format_image_suggestion(res)
        print(f"{name:<20} | {img_type:<12} | {desc:<18} | {suggestion}")
    print(f"{'='*60}")
    print_screenshot_tree(analysis_results)
    
    # --- ä¿å­˜è¯¦ç»†æŠ¥å‘Š ---
    try:
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write("å›¾ç‰‡æ·±åº¦åˆ†æä¸å»é‡è¯¦ç»†æŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}\n")
            f.write("="*60 + "\n\n")
            
            for res in analysis_results:
                name = Path(res['path']).name
                f.write(f"æ–‡ä»¶å: {name}\n")
                f.write(f"è·¯å¾„: {res['path']}\n")
                
                # åˆ†ç±»ä¿¡æ¯
                if not res.get('likely_screenshot'):
                    # çœŸå®ç…§ç‰‡
                    f.write(f"ç±»å‹: çœŸå®ç…§ç‰‡ï¼ˆBestShot å»é‡ï¼‰\n")
                    score = res.get('bestshot_score', 0)
                    f.write(f"è´¨é‡åˆ†æ•°: {score:.2f}\n")
                else:
                    # éç…§ç‰‡ç±»
                    category = res.get('category', 'saved')
                    category_cn = CATEGORY_CN.get(category, 'æ”¶è—ç±»')
                    f.write(f"ç±»å‹: {category_cn}\n")
                    if res.get('app_name'):
                        f.write(f"APP: {res['app_name']}\n")
                    delete_weight = CATEGORY_DELETE_WEIGHT.get(category, 0.3)
                    f.write(f"åˆ é™¤å€¾å‘: {delete_weight*100:.0f}%\n")
                
                # è§†è§‰æè¿°
                desc = res.get('short_description') or res.get('vl', {}).get('scene', '')
                if desc:
                    f.write(f"æè¿°: {desc}\n")
                
                # Delete Suggestion
                sug = res.get('suggestion', {})
                if sug.get('delete'):
                    f.write(f"âš ï¸ åˆ é™¤å»ºè®®: å»ºè®®åˆ é™¤ã€‚åŸå› : {sug.get('reason')}\n")
                
                f.write("-" * 40 + "\n")
        
        print(f"âœ… è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {log_file}")
            
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜è¯¦ç»†æŠ¥å‘Šå¤±è´¥: {e}")


def get_or_run_image_analysis(path: str) -> Dict[str, Any]:
    """è·å–ç¼“å­˜çš„å›¾ç‰‡åˆ†æç»“æœï¼Œå¦åˆ™è°ƒç”¨ ImageAnalyzer"""
    if image_analyzer is None:
        return {}
    if path in IMAGE_ANALYSIS_CACHE:
        return IMAGE_ANALYSIS_CACHE[path]
    try:
        res = image_analyzer.analyze_image_file(path)
        IMAGE_ANALYSIS_CACHE[path] = res
        return res
    except Exception as e:
        print(f"âš ï¸ è°ƒç”¨ ImageAnalyzer å¤±è´¥ï¼š{path} -> {e}")
        return {}


def image_analysis_to_text(res: Dict[str, Any]) -> str:
    """å°†å›¾ç‰‡åˆ†æç»“æœå‹ç¼©ä¸ºæ–‡æœ¬æ‘˜è¦ï¼ˆç”¨äºç›¸ä¼¼åº¦æ¯”è¾ƒï¼‰"""
    parts = []
    
    # æè¿°ä¿¡æ¯
    if res.get('short_description'):
        parts.append(res['short_description'])
    
    # ç±»å‹ä¿¡æ¯
    if not res.get('likely_screenshot'):
        parts.append("type:photo")
    else:
        category = res.get('category', 'saved')
        parts.append(f"type:{category}")
        if res.get('app_name'):
            parts.append(f"app:{res['app_name']}")
    
    return " | ".join(parts) if parts else Path(res.get('path', '')).stem


def mark_similar_photos(photo_items: List[Dict[str, Any]],
                        feature_high: float = 0.92,          #ç…§ç‰‡ç‰¹å¾ç›¸ä¼¼åº¦é˜ˆå€¼(é«˜) - é™ä½åˆ°0.92ä»¥è¯†åˆ«æ›´å¤šç›¸ä¼¼å›¾ç‰‡
                        feature_low: float = 0.88,           #ç…§ç‰‡ç‰¹å¾ç›¸ä¼¼åº¦é˜ˆå€¼(ä½) - é™ä½åˆ°0.88
                        embed_threshold: float = 0.85,       #embeddingç›¸ä¼¼åº¦é˜ˆå€¼ - é™ä½åˆ°0.85
                        desc_threshold: float = 0.83,        #ç…§ç‰‡æè¿°ç›¸ä¼¼åº¦é˜ˆå€¼ - é™ä½åˆ°0.83
                        phash_high: float = 0.90,            #pHashé«˜é˜ˆå€¼ - é™ä½åˆ°0.90
                        phash_low: float = 0.85,             #pHashä½é˜ˆå€¼ - é™ä½åˆ°0.85
                        hist_threshold: float = 0.80,        #HSVç›´æ–¹å›¾é˜ˆå€¼ - é™ä½åˆ°0.80
                        debug: bool = True):                 #è°ƒè¯•æ¨¡å¼
    """å¯¹ç…§ç‰‡è¿›è¡Œç›¸ä¼¼åº¦èšç±»ï¼Œä»…ä¿ç•™æ¯ä¸ªç°‡ä¸­çš„æœ€ä½³ç…§ç‰‡"""
    if len(photo_items) <= 1:
        return
    n = len(photo_items)
    features = []
    embeddings = []
    descriptions = []
    person_ids = []
    phashes = []
    hists = []
    
    if debug:
        print(f"\nğŸ” ç…§ç‰‡ç›¸ä¼¼åº¦åˆ†æï¼ˆå…± {n} å¼ ç…§ç‰‡ï¼‰")
        print(f"   é˜ˆå€¼è®¾ç½®ï¼š")
        print(f"      - ç…§ç‰‡ç‰¹å¾: high={feature_high}, low={feature_low}")
        print(f"      - pHash: high={phash_high}, low={phash_low}")
        print(f"      - HSVç›´æ–¹å›¾: {hist_threshold}")
        print(f"      - Embedding: {embed_threshold}")
        print(f"      - æè¿°ç›¸ä¼¼åº¦: {desc_threshold}")
    
    # å…ˆæ”¶é›†æ‰€æœ‰æ•°æ®
    for idx, res in enumerate(photo_items):
        feat = res.get('photo_feature')
        if feat is None:
            feat = compute_photo_feature(res['path'])
            res['photo_feature'] = feat
        features.append(feat)
        
        emb = res.get('embedding')
        embeddings.append(emb)
        
        # è°ƒè¯•ï¼šæ£€æŸ¥æ¯å¼ ç…§ç‰‡çš„ embedding
        if debug and idx < 3:  # æ‰“å°å‰3å¼ çš„è¯¦ç»†ä¿¡æ¯
            name = Path(res['path']).name
            print(f"\n      ğŸ“‹ ç…§ç‰‡ {idx+1}: {name}")
            print(f"         æœ‰ embedding: {emb is not None}")
            if emb is not None:
                print(f"         embedding ç±»å‹: {type(emb)}, é•¿åº¦: {len(emb) if hasattr(emb, '__len__') else 'N/A'}")
            else:
                print(f"         res ä¸­çš„æ‰€æœ‰é”®: {list(res.keys())}")
                if 'embedding' in res:
                    print(f"         embedding å€¼ä¸º: {res['embedding']}")
        
        descriptions.append(res.get('short_description') or res.get('vl', {}).get('scene', ''))
        person_ids.append(extract_person_identifier(res['path']))
        phashes.append(compute_phash_vector(res['path']))
        hists.append(compute_hsv_hist(res['path']))
    
    # ç»Ÿè®¡æ•°æ®çŠ¶æ€ï¼ˆåœ¨æ•°æ®æ”¶é›†å®Œæˆåï¼‰
    if debug:
        emb_count = sum(1 for e in embeddings if e is not None)
        feat_count = sum(1 for f in features if f is not None)
        print(f"\n   æ•°æ®çŠ¶æ€ï¼š")
        print(f"      - Embedding å¯ç”¨: {emb_count}/{n} å¼ ")
        print(f"      - ç…§ç‰‡ç‰¹å¾å¯ç”¨: {feat_count}/{n} å¼ ")
        if emb_count < n:
            print(f"      âš ï¸ è­¦å‘Šï¼šæœ‰ {n - emb_count} å¼ ç…§ç‰‡ç¼ºå°‘ embeddingï¼Œå¯èƒ½å½±å“ç›¸ä¼¼åº¦åˆ¤æ–­")
    
    parent = list(range(n))

    def find(x):
        while parent[x] != x:
            parent[x] = parent[parent[x]]
            x = parent[x]
        return x

    def union(a, b):
        ra, rb = find(a), find(b)
        if ra != rb:
            parent[rb] = ra

    similarity_details = []  # å­˜å‚¨ç›¸ä¼¼åº¦è¯¦æƒ…ç”¨äºè°ƒè¯•
    
    for i in range(n):
        fi = features[i]
        if fi is None:
            continue
        for j in range(i + 1, n):
            fj = features[j]
            if fj is None:
                continue
            if should_force_keep(person_ids[i], person_ids[j]):
                continue
            
            # è®¡ç®—æ‰€æœ‰ç»´åº¦çš„ç›¸ä¼¼åº¦
            photo_sim = photo_cosine_similarity(fi, fj)
            ph_sim = phash_similarity(phashes[i], phashes[j])
            hist_sim = histogram_similarity(hists[i], hists[j])
            embed_sim = embedding_cosine_similarity(embeddings[i], embeddings[j])
            desc_sim = short_desc_similarity(descriptions[i], descriptions[j])
            
            # å­˜å‚¨è¯¦æƒ…
            if debug:
                name_i = Path(photo_items[i]['path']).name
                name_j = Path(photo_items[j]['path']).name
                similarity_details.append({
                    'pair': (name_i, name_j),
                    'photo': photo_sim,
                    'phash': ph_sim,
                    'hist': hist_sim,
                    'embed': embed_sim,
                    'desc': desc_sim
                })
            
            # å¿«é€Ÿè¿‡æ»¤ï¼šå¦‚æœ pHash å’Œç…§ç‰‡ç‰¹å¾éƒ½å¤ªä½ï¼Œè·³è¿‡
            if ph_sim < phash_low and photo_sim < feature_low:
                continue
            
            # å¤šç»´åº¦åˆ¤æ–­ç›¸ä¼¼æ€§
            similar = False
            match_reason = ""
            
            if ph_sim >= phash_high and hist_sim >= hist_threshold:
                similar = True
                match_reason = f"pHashé«˜({ph_sim:.3f}) + ç›´æ–¹å›¾({hist_sim:.3f})"
            elif photo_sim >= feature_high and hist_sim >= hist_threshold:
                similar = True
                match_reason = f"ç‰¹å¾é«˜({photo_sim:.3f}) + ç›´æ–¹å›¾({hist_sim:.3f})"
            elif ph_sim >= phash_low and hist_sim >= hist_threshold and (photo_sim >= feature_low or embed_sim >= embed_threshold):
                similar = True
                match_reason = f"pHashä¸­({ph_sim:.3f}) + ç›´æ–¹å›¾({hist_sim:.3f}) + ç‰¹å¾/åµŒå…¥"
            elif embed_sim >= embed_threshold:
                similar = True
                match_reason = f"åµŒå…¥å‘é‡({embed_sim:.3f})"
            elif desc_sim >= desc_threshold:
                similar = True
                match_reason = f"æè¿°ç›¸ä¼¼({desc_sim:.3f})"
            
            if similar:
                union(i, j)
                if debug:
                    similarity_details[-1]['matched'] = True
                    similarity_details[-1]['reason'] = match_reason
            elif debug:
                similarity_details[-1]['matched'] = False
                similarity_details[-1]['reason'] = "æœªè¾¾é˜ˆå€¼"

    groups: Dict[int, List[Dict[str, Any]]] = {}
    for idx in range(n):
        root = find(idx)
        groups.setdefault(root, []).append(photo_items[idx])
    
    # è°ƒè¯•è¾“å‡ºï¼šæ˜¾ç¤ºç›¸ä¼¼åº¦è¯¦æƒ…
    if debug and similarity_details:
        print(f"\nğŸ“Š ç…§ç‰‡å¯¹ç›¸ä¼¼åº¦è¯¦æƒ…ï¼ˆå…± {len(similarity_details)} å¯¹ï¼‰ï¼š")
        # æŒ‰åŒ¹é…çŠ¶æ€åˆ†ç»„æ˜¾ç¤º
        matched = [d for d in similarity_details if d.get('matched')]
        unmatched = [d for d in similarity_details if not d.get('matched')]
        
        if matched:
            print(f"\n   âœ… åŒ¹é…çš„ç…§ç‰‡å¯¹ ({len(matched)} å¯¹)ï¼š")
            for detail in matched[:10]:  # åªæ˜¾ç¤ºå‰10å¯¹
                name_i, name_j = detail['pair']
                print(f"      {name_i} <-> {name_j}")
                print(f"         ç‰¹å¾={detail['photo']:.3f} | pHash={detail['phash']:.3f} | "
                      f"ç›´æ–¹å›¾={detail['hist']:.3f} | åµŒå…¥={detail['embed']:.3f} | æè¿°={detail['desc']:.3f}")
                print(f"         åŒ¹é…åŸå› : {detail['reason']}")
            if len(matched) > 10:
                print(f"      ... è¿˜æœ‰ {len(matched) - 10} å¯¹åŒ¹é…çš„ç…§ç‰‡")
        
        if unmatched:
            print(f"\n   âŒ æœªåŒ¹é…çš„ç…§ç‰‡å¯¹ ({len(unmatched)} å¯¹) - æ˜¾ç¤ºå‰10å¯¹ï¼š")
            for detail in unmatched[:10]:
                name_i, name_j = detail['pair']
                print(f"      {name_i} <-> {name_j}")
                print(f"         ç‰¹å¾={detail['photo']:.3f} | pHash={detail['phash']:.3f} | "
                      f"ç›´æ–¹å›¾={detail['hist']:.3f} | åµŒå…¥={detail['embed']:.3f} | æè¿°={detail['desc']:.3f}")
                # æ‰¾å‡ºå“ªäº›ç»´åº¦æ¥è¿‘é˜ˆå€¼
                close_to = []
                if detail['photo'] >= feature_low * 0.8:
                    close_to.append(f"ç‰¹å¾({detail['photo']:.3f}/{feature_low})")
                if detail['phash'] >= phash_low * 0.8:
                    close_to.append(f"pHash({detail['phash']:.3f}/{phash_low})")
                if detail['hist'] >= hist_threshold * 0.8:
                    close_to.append(f"ç›´æ–¹å›¾({detail['hist']:.3f}/{hist_threshold})")
                if detail['embed'] >= embed_threshold * 0.8:
                    close_to.append(f"åµŒå…¥({detail['embed']:.3f}/{embed_threshold})")
                if detail['desc'] >= desc_threshold * 0.8:
                    close_to.append(f"æè¿°({detail['desc']:.3f}/{desc_threshold})")
                if close_to:
                    print(f"         æ¥è¿‘é˜ˆå€¼: {', '.join(close_to)}")

    for group in groups.values():
        if len(group) < 2:
            continue
        best = max(group, key=lambda r: r.get('bestshot_score', 0))
        for item in group:
            if item is best:
                continue
            item.setdefault('suggestion', {})
            # åªåœ¨å°šæœªè¢«å…¶ä»–è§„åˆ™æ ‡è®°åˆ é™¤æ—¶è®¾ç½®ä¸ºåˆ é™¤
            if not item['suggestion'].get('delete'):
                item['suggestion']['delete'] = True
                item['suggestion']['reason'] = "ç›¸ä¼¼ç…§ç‰‡ï¼Œä»…ä¿ç•™æœ€ä½³é•œå¤´"
            item['duplicate_of'] = best['path']
    
    if debug:
        num_groups = len([g for g in groups.values() if len(g) >= 2])
        print(f"\nâœ… ç…§ç‰‡èšç±»å®Œæˆï¼šæ‰¾åˆ° {num_groups} ä¸ªç›¸ä¼¼ç»„")


def format_image_suggestion(res: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–å›¾ç‰‡å¤„ç†å»ºè®®"""
    suggestion = res.get('suggestion', {})
    
    # å¦‚æœæ ‡è®°ä¸ºåˆ é™¤
    if suggestion.get('delete'):
        if res.get('duplicate_of'):
            return f"ğŸ—‘ åˆ é™¤ï¼ˆç›¸ä¼¼ï¼Œä¿ç•™ {Path(res['duplicate_of']).name}ï¼‰"
        return f"ğŸ—‘ åˆ é™¤ï¼ˆ{suggestion.get('reason', 'å»ºè®®åˆ é™¤')}ï¼‰"
    
    # ä¿ç•™ï¼šæ˜¾ç¤ºè´¨é‡æˆ–åˆ†ç±»ä¿¡æ¯
    if not res.get('likely_screenshot'):
        # çœŸå®ç…§ç‰‡
        score = res.get('bestshot_score')
        return f"âœ… ä¿ç•™ï¼ˆè´¨é‡ {score:.2f}ï¼‰" if score else "âœ… ä¿ç•™"
    else:
        # éç…§ç‰‡ç±»
        category = res.get('category', 'saved')
        category_cn = CATEGORY_CN.get(category, 'æ”¶è—ç±»')
        app_name = res.get('app_name', '')
        detail = f"{category_cn} - {app_name}" if app_name else category_cn
        return f"âœ… ä¿ç•™ï¼ˆ{detail}ï¼‰"


def short_desc_similarity(a: str, b: str) -> float:
    if not a or not b:
        return 0.0
    ratio = SequenceMatcher(None, a, b).ratio()
    kw_sim = keyword_similarity(a, b)
    return 0.6 * ratio + 0.4 * kw_sim


def keyword_similarity(a: str, b: str) -> float:
    ka = extract_keywords(a)
    kb = extract_keywords(b)
    if not ka or not kb:
        return 0.0
    inter = ka & kb
    union = ka | kb
    return len(inter) / len(union)


def extract_keywords(text: str) -> set:
    tokens = re.findall(r"[A-Za-z]{3,}", text.lower())
    return set(tokens)


def is_cjk(char: str) -> bool:
    return '\u4e00' <= char <= '\u9fff'


def extract_person_identifier(path: str) -> str:
    stem = Path(path).stem
    tokens = re.split(r'[_\-\s]+', stem)
    for token in tokens:
        token = token.strip()
        if not token:
            continue
        cleaned = ''.join(ch for ch in token if ch.isalnum() or is_cjk(ch))
        if not cleaned:
            continue
        upper = cleaned.upper()
        if upper.startswith(('IMG', 'PXL', 'DSC', 'VID', 'PHOTO', 'SCREEN')):
            continue
        if any(is_cjk(ch) for ch in cleaned):
            name = ''.join(ch for ch in cleaned if is_cjk(ch))
            if name:
                return name
        if cleaned.isalpha() and len(cleaned) >= 3:
            return cleaned.lower()
    return ''


def should_force_keep(pid_a: str, pid_b: str) -> bool:
    return bool(pid_a and pid_b and pid_a != pid_b)


def compute_screenshot_clutter(res: Dict[str, Any]) -> float:
    text = (res.get('short_description') or '') + ' ' + (res.get('vl', {}).get('scene') or '')
    text = text.lower()
    keywords = [
        'video call', 'chat', 'message', 'popup', 'notification', 'toolbar',
        'window', 'menu', 'panel', 'comment', 'å¼¹å¹•', 'å¼¹çª—', 'èŠå¤©', 'é€šçŸ¥', 'çª—å£', 'èœå•'
    ]
    score = 0
    for kw in keywords:
        if kw in text:
            score += 1
    faces = res.get('vl', {}).get('faces')
    if isinstance(faces, (int, float)) and faces > 1:
        score += 0.5
    app_name = res.get('vl', {}).get('app_name')
    if isinstance(app_name, str) and any(tag in app_name.lower() for tag in ['zoom', 'teams', 'wechat', 'meeting']):
        score += 0.5
    score += (1.0 - res.get('bestshot_score', 0.0)) * 0.5
    return score


def mark_similar_screenshots(screenshot_items: List[Dict[str, Any]], desc_threshold: float = 0.85):
    """
    å¯¹æ ‡è®°ä¸º"ä¿ç•™"çš„æˆªå›¾è¿›è¡Œæ‚ä¹±åº¦å»é‡
    LLMå»ºè®®åˆ é™¤çš„æˆªå›¾ä¸å‚ä¸å»é‡ï¼Œç›´æ¥ä¿æŒåˆ é™¤çŠ¶æ€
    """
    if len(screenshot_items) <= 1:
        return
    
    # åªå¤„ç† LLM å»ºè®®ä¿ç•™çš„æˆªå›¾ï¼ˆsuggestion ä¸æ˜¯ 'delete' çš„ï¼‰
    keep_items = []
    keep_indices = []
    
    for idx, item in enumerate(screenshot_items):
        # ç›´æ¥ä» item ä¸­è¯»å– LLM åˆ†ç±»ç»“æœ
        sug_dict = item.get('suggestion', {})
        is_delete = sug_dict.get('delete', False)
        
        # å¦‚æœ LLM å»ºè®®åˆ é™¤ï¼Œç›´æ¥æ ‡è®°ä¸ºåˆ é™¤ï¼Œä¸è¿›å…¥å»é‡æµç¨‹
        if is_delete:
            # å·²ç»æ ‡è®°è¿‡äº†ï¼Œè·³è¿‡
            pass
        else:
            # LLM å»ºè®®ä¿ç•™çš„æˆªå›¾ï¼Œè¿›å…¥å»é‡æµç¨‹
            keep_items.append(item)
            keep_indices.append(idx)
    
    # å¦‚æœæ²¡æœ‰éœ€è¦å»é‡çš„æˆªå›¾ï¼Œç›´æ¥è¿”å›
    if len(keep_items) <= 1:
        return
    
    n = len(keep_items)
    parent = list(range(n))

    def find(x):
        while parent[x] != x:
            parent[x] = parent[parent[x]]
            x = parent[x]
        return x

    def union(a, b):
        ra, rb = find(a), find(b)
        if ra != rb:
            parent[rb] = ra

    # åªå¯¹ä¿ç•™çš„æˆªå›¾è¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒ
    descriptions = [
        item.get('short_description') or item.get('vl', {}).get('scene') or ''
        for item in keep_items
    ]
    app_names = [item.get('vl', {}).get('app_name') for item in keep_items]

    for i in range(n):
        for j in range(i + 1, n):
            desc_sim = short_desc_similarity(descriptions[i], descriptions[j])
            app_match = app_names[i] and app_names[i] == app_names[j]
            if desc_sim >= desc_threshold or app_match:
                union(i, j)

    groups: Dict[int, List[Dict[str, Any]]] = {}
    for idx in range(n):
        root = find(idx)
        groups.setdefault(root, []).append(keep_items[idx])

    for group in groups.values():
        if len(group) < 2:
            continue
        # åœ¨ä¿ç•™çš„æˆªå›¾ä¸­ï¼Œé€‰æ‹©æ‚ä¹±åº¦æœ€ä½çš„
        best = min(group, key=lambda r: (compute_screenshot_clutter(r), -r.get('bestshot_score', 0)))
        for item in group:
            if item is best:
                continue
            desc_sim = short_desc_similarity(
                item.get('short_description') or '',
                best.get('short_description') or ''
            )
            app_same = (item.get('vl', {}).get('app_name') or '') == (best.get('vl', {}).get('app_name') or '')
            if desc_sim >= 0.98 and app_same:
                sug = item.setdefault('suggestion', {})
                if not sug.get('delete'):
                    sug['delete'] = True
                    sug['reason'] = f"ç›¸ä¼¼æˆªå›¾ï¼Œä¿ç•™æ›´å¹²å‡€çš„ç‰ˆæœ¬ {Path(best['path']).name}"
                    item['duplicate_of'] = best['path']


def print_screenshot_tree(results: List[Dict[str, Any]]):
    """æ˜¾ç¤ºå›¾ç‰‡åˆ†ç±»æ ‘çŠ¶ç»“æ„ï¼ˆçœŸå®ç…§ç‰‡ + éç…§ç‰‡å››åˆ†ç±»ï¼‰"""
    real_photos_list = []
    non_photo_tree: Dict[str, List[str]] = {
        "ä¸´æ—¶ç±»": [],
        "å‚è€ƒç±»": [],
        "æ”¶è—ç±»": [],
        "è®°å¿†ç±»": []
    }
    
    for res in results:
        is_real_photo = not res.get('likely_screenshot', False)
        filename = Path(res['path']).name
        
        if is_real_photo:
            # çœŸå®ç…§ç‰‡
            score = res.get('bestshot_score')
            suggestion_text = "åˆ é™¤" if res.get('suggestion', {}).get('delete') else "ä¿ç•™"
            reason = ""
            if res.get('suggestion', {}).get('reason') and res.get('suggestion', {}).get('delete'):
                reason = f" - {res['suggestion']['reason']}"
            
            if score is not None:
                entry = f"{filename} [{suggestion_text}] (è´¨é‡ {score:.2f}){reason}"
            else:
                entry = f"{filename} [{suggestion_text}]{reason}"
            
            real_photos_list.append(entry)
        else:
            # éç…§ç‰‡ç±»ï¼ˆç›´æ¥ä» res ä¸­è¯»å–ï¼‰
            category_en = res.get('category', 'saved').lower()
            category_cn = CATEGORY_CN.get(category_en, 'æ”¶è—ç±»')
            
            # ä» suggestion å­—å…¸ä¸­åˆ¤æ–­
            sug_dict = res.get('suggestion', {})
            is_delete = sug_dict.get('delete', False)
            suggestion = translate_suggestion('delete' if is_delete else 'keep')
            app_name = res.get('app_name', '')
            
            reason = ""
            if res.get('suggestion', {}).get('reason') and res.get('suggestion', {}).get('delete'):
                reason = f" - {res['suggestion']['reason']}"
            
            # æ„å»ºæ¡ç›®ï¼šæ–‡ä»¶å [å»ºè®®] (APPå) åŸå› 
            if app_name:
                entry = f"{filename} [{suggestion}] ({app_name}){reason}"
            else:
                entry = f"{filename} [{suggestion}]{reason}"
            
            non_photo_tree[category_cn].append(entry)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
    has_photos = len(real_photos_list) > 0
    has_non_photos = any(len(files) > 0 for files in non_photo_tree.values())
    
    if not has_photos and not has_non_photos:
        return
    
    print("\nğŸ“‚ å›¾ç‰‡åˆ†ç±»æ±‡æ€»")
    
    # æ˜¾ç¤ºçœŸå®ç…§ç‰‡
    if has_photos:
        print(f"\nğŸ“¸ ã€çœŸå®ç…§ç‰‡ã€‘({len(real_photos_list)} å¼ ) - ä½¿ç”¨ BestShot å»é‡")
        for entry in sorted(real_photos_list):
            print(f"  - {entry}")
    
    # æ˜¾ç¤ºéç…§ç‰‡ç±»ï¼ˆæŒ‰åˆ é™¤å¯èƒ½æ€§ï¼‰
    if has_non_photos:
        print(f"\nğŸ“± ã€éç…§ç‰‡ç±»ã€‘ï¼ˆæŒ‰åˆ é™¤å¯èƒ½æ€§æ’åºï¼‰")
        
        categories_order = [
            ("ä¸´æ—¶ç±»", "ğŸ—‘ï¸", "åˆ é™¤å¯èƒ½æ€§æœ€é«˜"),
            ("å‚è€ƒç±»", "ğŸ“‹", "åˆ é™¤å¯èƒ½æ€§ä¸­é«˜"),
            ("æ”¶è—ç±»", "ğŸ’¾", "åˆ é™¤å¯èƒ½æ€§ä¸­ä½"),
            ("è®°å¿†ç±»", "â“", "æ‰«æä»¶ç­‰é‡è¦å†…å®¹")
        ]
        
        for category, icon, desc in categories_order:
            files = non_photo_tree[category]
            if files:
                print(f"\n{icon} ã€{category}ã€‘({len(files)} å¼ ) - {desc}")
                for entry in sorted(files):
                    print(f"  - {entry}")


def translate_suggestion(text: str) -> str:
    """å°†è‹±æ–‡å»ºè®®è½¬æ¢ä¸ºä¸­æ–‡"""
    translations = {"keep": "ä¿ç•™", "delete": "åˆ é™¤"}
    return translations.get(text.lower(), text)


def analyze_similar_files_with_llm(file1: Dict, file2: Dict, similarity: float) -> str:
    """
    è°ƒç”¨å¤§æ¨¡å‹åˆ†æä¸¤ä¸ªç›¸ä¼¼æ–‡ä»¶çš„ç›¸åŒå’Œä¸åŒå†…å®¹
    
    æ³¨æ„ï¼šæ­¤å‡½æ•°ä½¿ç”¨åŸå§‹æ–‡æœ¬å†…å®¹ï¼ˆfile['content']ï¼‰ï¼Œè€Œä¸æ˜¯embeddingå‘é‡ã€‚
    å› ä¸ºï¼š
    1. Embeddingå‘é‡æ˜¯æ•°å€¼å‘é‡ï¼Œæ— æ³•ç›´æ¥ç”¨äºLLMçš„æ–‡æœ¬åˆ†æ
    2. LLMéœ€è¦çœ‹åˆ°å®é™…æ–‡æœ¬å†…å®¹æ‰èƒ½ç†è§£è¯­ä¹‰ã€è¯†åˆ«å·®å¼‚ã€ç”Ÿæˆè¯¦ç»†åˆ†æ
    
    ä½¿ç”¨æ™ºèƒ½æˆªå–ç­–ç•¥ï¼š
    1. å¦‚æœæ–‡ä»¶è¾ƒçŸ­ï¼ˆ<15000å­—ç¬¦ï¼‰ï¼Œä½¿ç”¨å®Œæ•´å†…å®¹
    2. å¦‚æœæ–‡ä»¶è¾ƒé•¿ï¼Œä½¿ç”¨å¼€å¤´+ç»“å°¾+ä¸­é—´å…³é”®éƒ¨åˆ†
    """
    # æ™ºèƒ½æˆªå–ç­–ç•¥ï¼šå¯¹äºé•¿æ–‡æœ¬ï¼Œæå–å¼€å¤´ã€ç»“å°¾å’Œä¸­é—´éƒ¨åˆ†
    def smart_truncate(content: str, max_chars: int = 15000) -> str:
        """æ™ºèƒ½æˆªå–æ–‡æœ¬ï¼Œä¿ç•™å¼€å¤´ã€ç»“å°¾å’Œä¸­é—´å…³é”®éƒ¨åˆ†"""
        if len(content) <= max_chars:
            return content
        
        # è®¡ç®—å„éƒ¨åˆ†é•¿åº¦
        part_size = max_chars // 3  # æ¯éƒ¨åˆ†çº¦1/3
        
        # æå–å¼€å¤´ã€ä¸­é—´ã€ç»“å°¾
        start_part = content[:part_size]
        middle_start = len(content) // 2 - part_size // 2
        middle_part = content[middle_start:middle_start + part_size]
        end_part = content[-part_size:]
        
        return f"{start_part}\n\n[... ä¸­é—´éƒ¨åˆ†çœç•¥ ...]\n\n{middle_part}\n\n[... ä¸­é—´éƒ¨åˆ†çœç•¥ ...]\n\n{end_part}"
    
    content1 = smart_truncate(file1['content'])
    content2 = smart_truncate(file2['content'])
    
    # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„å­—ç¬¦æ•°
    original_len1 = len(file1['content'])
    original_len2 = len(file2['content'])
    used_len1 = len(content1)
    used_len2 = len(content2)
    
    if original_len1 > used_len1 or original_len2 > used_len2:
        print(f"   â„¹ï¸ æ–‡ä»¶å†…å®¹è¾ƒé•¿ï¼Œä½¿ç”¨æ™ºèƒ½æˆªå–è¿›è¡Œåˆ†æï¼š")
        print(f"      æ–‡ä»¶1: {used_len1}/{original_len1} å­—ç¬¦")
        print(f"      æ–‡ä»¶2: {used_len2}/{original_len2} å­—ç¬¦")
    
    prompt = f"""ä½ æ˜¯æ–‡ä»¶å†…å®¹åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹ä¸¤ä¸ªç›¸ä¼¼æ–‡ä»¶çš„å†…å®¹ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

    1. æ€»ç»“ä¸¤ä¸ªæ–‡ä»¶çš„ç›¸åŒå†…å®¹ï¼ˆå…±åŒç‚¹ï¼‰
    2. åˆ†åˆ«æ€»ç»“æ¦‚è¿°æ–‡ä»¶1çš„ä¸åŒå†…å®¹ï¼ˆæ–‡ä»¶1ç‹¬æœ‰çš„å†…å®¹ï¼‰
    3. åˆ†åˆ«æ€»ç»“æ¦‚è¿°æ–‡ä»¶2çš„ä¸åŒå†…å®¹ï¼ˆæ–‡ä»¶2ç‹¬æœ‰çš„å†…å®¹ï¼‰

    ã€æ–‡ä»¶1ã€‘
    æ–‡ä»¶åï¼š{file1['name']}
    å†…å®¹é•¿åº¦ï¼š{original_len1} å­—ç¬¦
    å†…å®¹ï¼š
    {content1}

    ã€æ–‡ä»¶2ã€‘
    æ–‡ä»¶åï¼š{file2['name']}
    å†…å®¹é•¿åº¦ï¼š{original_len2} å­—ç¬¦
    å†…å®¹ï¼š
    {content2}

    ã€ç›¸ä¼¼åº¦ã€‘
    ä¸¤ä¸ªæ–‡ä»¶çš„ä½™å¼¦ç›¸ä¼¼åº¦ä¸ºï¼š{similarity:.3f}

    æ³¨æ„ï¼šå¦‚æœæ–‡ä»¶å†…å®¹è¾ƒé•¿ï¼Œå¯èƒ½åªæ˜¾ç¤ºäº†éƒ¨åˆ†å†…å®¹ï¼ˆå¼€å¤´ã€ä¸­é—´å’Œç»“å°¾éƒ¨åˆ†ï¼‰ã€‚è¯·åŸºäºæä¾›çš„å†…å®¹è¿›è¡Œåˆ†æï¼Œå¦‚æœå‘ç°å†…å®¹ä¸å®Œæ•´ï¼Œè¯·åœ¨åˆ†æç»“æœä¸­è¯´æ˜ã€‚

    è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
    ã€ç›¸åŒå†…å®¹ã€‘
    ...

    ã€æ–‡ä»¶1çš„ä¸åŒå†…å®¹ã€‘
    ...

    ã€æ–‡ä»¶2çš„ä¸åŒå†…å®¹ã€‘
    ...
    """
    
    try:
        response = chat_client.chat.completions.create(
            model=LLM_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0  # ä½¿ç”¨0.0ç¡®ä¿è·¨å¹³å°ç»“æœä¸€è‡´
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ LLM åˆ†æå¤±è´¥: {e}")
        return f"åˆ†æå¤±è´¥: {str(e)}"


def process_directory(target_dir: Path = TEST_DIR, log_callback=None):
    """ä¸»å¤„ç†å‡½æ•°ï¼Œæ¥æ”¶ç›®æ ‡ç›®å½•ä½œä¸ºå‚æ•°"""
    def log(msg):
        if log_callback:
            log_callback(msg)
        else:
            print(msg)

    log("ğŸš€ ç›¸ä¼¼æ–‡ä»¶è¯†åˆ«å·¥å…·å¯åŠ¨ä¸­...")

    # äºŒæ¬¡è¿è¡Œé˜²æŠ¤ï¼šæ‰“åŒ…/GUI åœºæ™¯ä¸‹åŒä¸€è¿›ç¨‹å¯èƒ½é‡å¤è°ƒç”¨æœ¬å‡½æ•°ã€‚
    # æ¸…ç†è¿è¡Œæ€ç¼“å­˜ï¼Œé¿å…ä¸Šä¸€æ¬¡è¿è¡Œçš„ç¼“å­˜/ä¸­é—´ç»“æœå½±å“ä¸‹ä¸€æ¬¡è¿è¡Œï¼Œç”šè‡³è§¦å‘å¼‚å¸¸ã€‚
    try:
        IMAGE_ANALYSIS_CACHE.clear()
        PHOTO_FEATURE_CACHE.clear()
        PHOTO_PHASH_CACHE.clear()
        PHOTO_HIST_CACHE.clear()
    except Exception:
        # ç¼“å­˜æ¸…ç†å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
        pass
    
    # æ‰«ææ–‡ä»¶
    test_dir_str = str(target_dir)
    log(f"\nğŸ“ æ­£åœ¨æ‰«æç›®å½•: {test_dir_str}")
    file_infos = scan_files(target_dir)
    
    if len(file_infos) == 0:
        log("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
        return []
    
    log(f"âœ… æ‰¾åˆ° {len(file_infos)} ä¸ªæ–‡ä»¶")
    
    # === å›¾ç‰‡æ·±åº¦åˆ†æä¸å»é‡ ===
    image_results = []
    
    # å¯ç”¨å›¾ç‰‡åˆ†æ
    try:
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•ç”¨äº analyze_and_report_images
        temp_out = target_dir / "logs"
        temp_out.mkdir(exist_ok=True)
        
        log(f"ğŸ–¼ï¸ å¼€å§‹æ‰«æå¹¶åˆ†æå›¾ç‰‡ (BestShot å»é‡)...")
        # ä¿®æ”¹ analyze_and_report_images ä»¥è¿”å›ç»“æ„åŒ–æ•°æ®è€Œéä»…æ‰“å°
        # ç”±äºåŸå‡½æ•°è®¾è®¡ä¸ºæ‰“å°ï¼Œæˆ‘ä»¬è¿™é‡Œç®€å•åŒ…è£…ä¸€ä¸‹é€»è¾‘
        # ä¸ºäº†ä¸å¤§å¹…ä¿®æ”¹åŸå‡½æ•°ç­¾åå¯¼è‡´å…¶ä»–åœ°æ–¹æŠ¥é”™ï¼Œæˆ‘ä»¬è¿™é‡Œç›´æ¥è°ƒç”¨æ ¸å¿ƒé€»è¾‘
        
        if image_analyzer:
            images = [f for f in file_infos if Path(f['path']).suffix.lower() in IMAGE_EXTENSIONS]
            if images:
                log(f"   å‘ç° {len(images)} å¼ å›¾ç‰‡ï¼Œæ­£åœ¨è¿›è¡Œè§†è§‰ç†è§£ä¸è´¨é‡è¯„ä¼°...")
                analyzed_images = []
                pbar = tqdm(images, desc="åˆ†æå›¾ç‰‡")
                for img in pbar:
                    res = get_or_run_image_analysis(img['path'])
                    
                    # åˆ¤æ–­ï¼šçœŸå®ç…§ç‰‡ or éç…§ç‰‡ç±»
                    is_real_photo = not res.get('likely_screenshot', False)
                    
                    if is_real_photo:
                        # çœŸå®ç…§ç‰‡ â†’ è¡¥å…¨ç‰¹å¾
                        if not res.get('photo_feature'):
                            res['photo_feature'] = compute_photo_feature(img['path'])
                        pbar.set_postfix_str(f"ğŸ“¸ ç…§ç‰‡")
                    else:
                        # éç…§ç‰‡ç±» â†’ LLM å››åˆ†ç±»
                        try:
                            pbar.set_postfix_str(f"ğŸ¤– åˆ†ç±»æˆªå›¾...")
                            llm_result = image_analyzer.screenshot_classify_with_llm(res)
                            res['category'] = llm_result.get('category', 'saved')
                            res['app_name'] = llm_result.get('app_name', '')
                            
                            category_cn = CATEGORY_CN.get(res['category'], 'æœªçŸ¥')
                            suggestion_text = llm_result.get('suggestion', 'keep')
                            pbar.set_postfix_str(f"âœ… {category_cn}")
                            
                            # LLM å»ºè®®åˆ é™¤ â†’ æ ‡è®°
                            if llm_result.get('suggestion') == 'delete':
                                res.setdefault('suggestion', {})
                                res['suggestion']['delete'] = True
                                res['suggestion']['reason'] = f'LLMå»ºè®®åˆ é™¤ï¼ˆ{category_cn}ï¼‰'
                        except Exception as e:
                            pbar.set_postfix_str(f"âš ï¸ åˆ†ç±»å¤±è´¥")
                            tqdm.write(f"         âš ï¸ LLMåˆ†ç±»å¤±è´¥: {e}")
                            import traceback
                            tqdm.write(traceback.format_exc())
                            res['category'] = 'saved'
                            res['app_name'] = ''
                    
                    # è¡¥å…¨ embedding
                    if res.get('embedding'):
                        img['embedding'] = res['embedding']
                    
                    analyzed_images.append(res)
                
                # æ‰§è¡Œèšç±»æ ‡è®°
                real_photos = [r for r in analyzed_images if not r.get('likely_screenshot')]
                non_photos = [r for r in analyzed_images if r.get('likely_screenshot')]
                
                log(f"   ğŸ“¸ çœŸå®ç…§ç‰‡: {len(real_photos)} å¼ ")
                log(f"   ğŸ“± æˆªå›¾/éç…§ç‰‡: {len(non_photos)} å¼ ")
                
                # ç»Ÿè®¡æˆªå›¾åˆ†ç±»åˆ†å¸ƒ
                if non_photos:
                    category_stats = {'temporary': 0, 'reference': 0, 'saved': 0, 'memory': 0}
                    for item in non_photos:
                        cat = item.get('category', 'saved')
                        category_stats[cat] = category_stats.get(cat, 0) + 1
                    log(f"   ğŸ“Š æˆªå›¾åˆ†ç±»ç»Ÿè®¡:")
                    log(f"      ğŸ—‘ï¸ ä¸´æ—¶ç±»: {category_stats['temporary']} å¼ ")
                    log(f"      ğŸ“‹ å‚è€ƒç±»: {category_stats['reference']} å¼ ")
                    log(f"      ğŸ’¾ æ”¶è—ç±»: {category_stats['saved']} å¼ ")
                    log(f"      â“ è®°å¿†ç±»: {category_stats['memory']} å¼ ")
                
                mark_similar_photos(real_photos, debug=False)
                mark_similar_screenshots(non_photos)
                
                # === æ”¶é›†ç…§ç‰‡ç›¸ä¼¼ç»„ ===
                photo_groups = {}
                for item in real_photos:
                    if item.get('duplicate_of'):
                        target = item['duplicate_of']
                        photo_groups.setdefault(target, []).append(item)
                
                for target_path, dup_items in photo_groups.items():
                    # æŸ¥æ‰¾ target çš„å…ƒä¿¡æ¯ (é€šè¿‡ target_path)
                    target_item = next((r for r in real_photos if r['path'] == target_path), None)
                    
                    # æ„å»ºæ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å«pathã€suggestionå’Œå…ƒä¿¡æ¯ï¼‰
                    files_info = [{
                        "path": target_path, 
                        "name": Path(target_path).name,
                        "size": target_item.get('size', 0) if target_item else 0,
                        "mtime": target_item.get('mtime', 0) if target_item else 0,
                        "suggestion": "ä¿ç•™"
                    }]
                    for dup in dup_items:
                        files_info.append({
                            "path": dup['path'],
                            "name": Path(dup['path']).name,
                            "size": dup.get('size', 0),
                            "mtime": dup.get('mtime', 0),
                            "suggestion": "åˆ é™¤"
                        })
                    image_results.append({
                        "type": "photo_group",
                        "files": files_info,
                        "best_shot": target_path
                    })
                
                # === æ”¶é›†æˆªå›¾åˆ†ç±»ç»“æœï¼ˆæŒ‰å››åˆ†ç±»ç»„ç»‡ï¼‰ ===
                # 1. æ‚ä¹±åº¦å»é‡ç»„ï¼ˆç›¸ä¼¼æˆªå›¾ï¼‰
                screenshot_dedup_groups = {}
                for item in non_photos:
                    if item.get('duplicate_of'):
                        target = item['duplicate_of']
                        screenshot_dedup_groups.setdefault(target, []).append(item)
                
                for target_path, dup_items in screenshot_dedup_groups.items():
                    # æŸ¥æ‰¾ target çš„å…ƒä¿¡æ¯
                    target_item = next((r for r in non_photos if r['path'] == target_path), None)
                    
                    files_info = [{
                        "path": target_path, 
                        "name": Path(target_path).name,
                        "size": target_item.get('size', 0) if target_item else 0,
                        "mtime": target_item.get('mtime', 0) if target_item else 0,
                        "suggestion": "ä¿ç•™"
                    }]
                    for dup in dup_items:
                        files_info.append({
                            "path": dup['path'],
                            "name": Path(dup['path']).name,
                            "size": dup.get('size', 0),
                            "mtime": dup.get('mtime', 0),
                            "suggestion": "åˆ é™¤"
                        })
                    image_results.append({
                        "type": "screenshot_dedup_group",
                        "files": files_info,
                        "best_shot": target_path
                    })
                
                # 2. æŒ‰å››åˆ†ç±»æ”¶é›†æ‰€æœ‰æˆªå›¾ï¼ˆå±•ç¤ºç»™ç”¨æˆ·å†³ç­–ï¼‰
                screenshot_by_category = {
                    'temporary': [],
                    'reference': [],
                    'saved': [],
                    'memory': []
                }
                
                for item in non_photos:
                    # è·³è¿‡å·²ç»åœ¨å»é‡ç»„ä¸­çš„æˆªå›¾
                    if item.get('duplicate_of'):
                        continue
                    
                    sug = item.get('suggestion', {})
                    category = item.get('category', 'saved')
                    
                    # éªŒè¯å¹¶æ ‡å‡†åŒ– categoryï¼Œé˜²æ­¢æ„å¤–å€¼å¯¼è‡´ KeyError
                    # å¤„ç†å¯èƒ½çš„æ—§åˆ†ç±»æˆ– LLM è¿”å›çš„æ„å¤–å€¼
                    if category not in ['temporary', 'reference', 'saved', 'memory']:
                        category_mapping = {
                            'screenshot': 'temporary',
                            'software': 'temporary',
                            'flowchart': 'reference',
                            'document': 'reference',
                            'photo': 'memory',
                            'other': 'saved'
                        }
                        category = category_mapping.get(category.lower() if isinstance(category, str) else category, 'saved')
                    
                    # æ‰€æœ‰æˆªå›¾éƒ½æ”¶é›†ï¼Œä¸ç®¡æ˜¯å¦å»ºè®®åˆ é™¤
                    # è®©ç”¨æˆ·çœ‹åˆ°å®Œæ•´çš„åˆ†ç±»ç»“æœå¹¶è‡ªå·±å†³å®š
                    is_delete = sug.get('delete', False)
                    screenshot_by_category[category].append({
                        "path": item['path'],
                        "name": Path(item['path']).name,
                        "size": item.get('size', 0),
                        "mtime": item.get('mtime', 0),
                        "suggestion": "åˆ é™¤" if is_delete else "ä¿ç•™",
                        "reason": sug.get('reason', '') if is_delete else f"LLMå»ºè®®ä¿ç•™"
                    })
                
                # æŒ‰åˆ†ç±»åˆ›å»ºå¡ç‰‡ç»„ï¼ˆåªåˆ›å»ºæœ‰å†…å®¹çš„åˆ†ç±»ï¼‰
                category_labels = {
                    'temporary': 'ğŸ—‘ï¸ ä¸´æ—¶ç±»æˆªå›¾ï¼ˆåˆ é™¤å€¾å‘90%ï¼‰',
                    'reference': 'ğŸ“‹ å‚è€ƒç±»æˆªå›¾ï¼ˆåˆ é™¤å€¾å‘60%ï¼‰',
                    'saved': 'ğŸ’¾ æ”¶è—ç±»æˆªå›¾ï¼ˆåˆ é™¤å€¾å‘30%ï¼‰',
                    'memory': 'â“ è®°å¿†ç±»æˆªå›¾ï¼ˆåˆ é™¤å€¾å‘10%ï¼‰'
                }
                
                for cat in ['temporary', 'reference', 'saved', 'memory']:
                    if screenshot_by_category[cat]:
                        image_results.append({
                            "type": "screenshot_category",
                            "category": cat,
                            "label": category_labels[cat],
                            "files": screenshot_by_category[cat]
                        })
                
                log(f"âœ… å›¾ç‰‡åˆ†æå®Œæˆï¼Œå‘ç° {len(image_results)} ç»„ç»“æœ")
                log(f"   - ç›¸ä¼¼ç…§ç‰‡ç»„: {len([r for r in image_results if r['type'] == 'photo_group'])} ç»„")
                log(f"   - æˆªå›¾å»é‡ç»„: {len([r for r in image_results if r['type'] == 'screenshot_dedup_group'])} ç»„")
                log(f"   - ä¸´æ—¶ç±»æˆªå›¾: {len(screenshot_by_category['temporary'])} å¼ ")
                log(f"   - å‚è€ƒç±»æˆªå›¾: {len(screenshot_by_category['reference'])} å¼ ")
                log(f"   - æ”¶è—ç±»æˆªå›¾: {len(screenshot_by_category['saved'])} å¼ ")
                log(f"   - è®°å¿†ç±»æˆªå›¾: {len(screenshot_by_category['memory'])} å¼ ")
            else:
                log("â„¹ï¸ æœªå‘ç°å›¾ç‰‡æ–‡ä»¶")
    except Exception as e:
        log(f"âš ï¸ å›¾ç‰‡åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        log(traceback.format_exc())

    # ä»…å¯¹éå›¾ç‰‡æ–‡ä»¶æ‰§è¡Œç›¸ä¼¼åº¦æµç¨‹
    text_like_files = [
        f for f in file_infos
        if Path(f['path']).suffix.lower() not in IMAGE_EXTENSIONS
    ]

    results = []
    if len(text_like_files) < 2:
        log("â„¹ï¸ æ–‡æœ¬æ–‡ä»¶ä¸è¶³ï¼Œè·³è¿‡è¯­ä¹‰åˆ†æ")
        similar_pairs = []
    else:
        # æŸ¥æ‰¾ç›¸ä¼¼æ–‡ä»¶å¯¹
        log(f"ğŸ” æ­£åœ¨åˆ†æ {len(text_like_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶çš„ç›¸ä¼¼åº¦...")
        similar_pairs = find_similar_file_pairs(text_like_files, SIMILARITY_THRESHOLD)

    if not similar_pairs:
        log(f"âœ… æœªæ‰¾åˆ°ç›¸ä¼¼åº¦ >= {SIMILARITY_THRESHOLD} çš„æ–‡ä»¶å¯¹")
    else:
        log(f"âœ… æ‰¾åˆ° {len(similar_pairs)} å¯¹ç›¸ä¼¼æ–‡ä»¶")
        log("ğŸ¤– æ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹åˆ†æç›¸ä¼¼æ–‡ä»¶å·®å¼‚...")

        for i, (file1, file2, similarity) in enumerate(similar_pairs, 1):
            log(f"ğŸ“Š åˆ†æç¬¬ {i}/{len(similar_pairs)} å¯¹: {file1['name']} <-> {file2['name']}")
            analysis = analyze_similar_files_with_llm(file1, file2, similarity)
            results.append({
                "file1": file1,
                "file2": file2,
                "similarity": similarity,
                "analysis": analysis
            })

        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆä½¿ç”¨æ—¶é—´æˆ³é¿å…äºŒæ¬¡è¿è¡Œè¦†ç›–/æ–‡ä»¶å ç”¨å¯¼è‡´å¤±è´¥ï¼‰
        try:
            logs_dir = target_dir / "logs"
            logs_dir.mkdir(exist_ok=True)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = logs_dir / f"similar_files_analysis_{ts}.txt"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("ç›¸ä¼¼æ–‡ä»¶åˆ†æç»“æœ\n")
                f.write("=" * 60 + "\n\n")
                for result in results:
                    f.write(f"æ–‡ä»¶å¯¹: {result['file1']} <-> {result['file2']}\n")
                    f.write(f"ç›¸ä¼¼åº¦: {result['similarity']:.3f}\n")
                    f.write("-" * 60 + "\n")
                    f.write(result['analysis'])
                    f.write("\n\n" + "=" * 60 + "\n\n")
            log(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_file.name}")
        except Exception as e:
            log(f"âš ï¸ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

    # åˆå¹¶å›¾ç‰‡ç»“æœå’Œæ–‡æœ¬ç»“æœ
    return results + image_results


def main():
    """ä¸»å‡½æ•°"""
    process_directory()


def diagnose_environment():
    """è¯Šæ–­ç¯å¢ƒé…ç½®ï¼Œæ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…"""
    print("=" * 60)
    print("ğŸ” ç¯å¢ƒè¯Šæ–­")
    print("=" * 60)
    
    # æ£€æŸ¥ Python åŒ…
    print("\nğŸ“¦ Python åŒ…æ£€æŸ¥:")
    packages = {
        "PyPDF2": PdfReader is not None,
        "pypdfium2": pdfium is not None,
        "PIL/Pillow": Image is not None,
        "numpy": np is not None,
    }
    
    for name, installed in packages.items():
        status = "âœ…" if installed else "âŒ"
        print(f"   {status} {name}: {'å·²å®‰è£…' if installed else 'æœªå®‰è£…'}")
    
    # æ£€æŸ¥ API å¯†é’¥
    print("\nğŸ”‘ API å¯†é’¥æ£€æŸ¥:")
    dashscope_key = os.getenv("DASHSCOPE_API_KEY")
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    print(f"   {'âœ…' if dashscope_key else 'âŒ'} DASHSCOPE_API_KEY: {'å·²è®¾ç½®' if dashscope_key else 'æœªè®¾ç½®'}")
    print(f"   {'âœ…' if deepseek_key else 'âŒ'} DEEPSEEK_API_KEY: {'å·²è®¾ç½®' if deepseek_key else 'æœªè®¾ç½®'}")
    
    # OCR é…ç½®
    print("\nğŸ”¤ OCR é…ç½®:")
    print(f"   - OCR æ¨¡å‹: {OCR_MODEL} (åœ¨çº¿API)")
    print(f"   - PDF æ¸²æŸ“åˆ†è¾¨ç‡: {int(PDF_RENDER_SCALE * 72)} DPI")
    print(f"   - PDF OCR é¡µæ•°é™åˆ¶: {'å…¨éƒ¨é¡µ' if MAX_PDF_OCR_PAGES is None else f'å‰ {MAX_PDF_OCR_PAGES} é¡µ'}")
    
    # ç›¸ä¼¼åº¦æ¯”è¾ƒé…ç½®
    print("\nğŸ” ç›¸ä¼¼åº¦æ¯”è¾ƒé…ç½®:")
    print(f"   - æ–‡å­—å±‚é¢ç›¸ä¼¼åº¦é˜ˆå€¼: {TEXT_SIMILARITY_THRESHOLD} (ç”¨äºåˆæ­¥ç­›é€‰)")
    print(f"   - è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼: {SIMILARITY_THRESHOLD} (ç”¨äºæœ€ç»ˆåˆ¤æ–­)")
    
    # Embedding é…ç½®
    print("\nğŸ“Š Embedding é…ç½®:")
    print(f"   - æ¨¡å‹: {EMBED_MODEL}")
    print(f"   - æœ€å¤§ Token æ•°: {EMBEDDING_MAX_TOKENS}")
    print(f"   - åˆ†å—å¤§å°: {EMBEDDING_CHUNK_SIZE} å­—ç¬¦")
    print(f"   - åˆ†å—é‡å : {EMBEDDING_CHUNK_OVERLAP} å­—ç¬¦")
    
    print("\n" + "=" * 60)


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--diagnose":
        diagnose_environment()
    else:
        main()

