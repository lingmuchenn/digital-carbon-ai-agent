import argparse
import json
import os
import re
import sys
import time
from dataclasses import dataclass
from difflib import SequenceMatcher
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple


# =========================
# åŸºç¡€é…ç½®
# =========================
ARCHIVE_EXTS = {".zip", ".rar", ".7z"}
INSTALLER_EXTS = {".dmg", ".pkg", ".exe", ".msi", ".apk"}
EDITABLE_SOURCE_EXTS = {".docx", ".doc", ".pptx", ".ppt", ".xls", ".xlsx", ".png", ".jpg"}
OPEN_WITHIN_MINUTES = 30


@dataclass
class FileInfo:
    path: Path
    name: str
    stem: str
    ext: str
    parent: Path
    size: int
    ctime: float
    mtime: float
    atime: float


def _safe_print(msg: str):
    try:
        print(msg)
    except UnicodeEncodeError:
        enc = getattr(sys.stdout, "encoding", None) or "utf-8"
        try:
            safe_msg = msg.encode(enc, errors="replace").decode(enc, errors="replace")
        except Exception:
            safe_msg = msg.encode("utf-8", errors="replace").decode("utf-8", errors="replace")
        print(safe_msg)


def get_default_download_dirs() -> List[Path]:
    """æ ¹æ®ç³»ç»Ÿæ¨æ–­é»˜è®¤ä¸‹è½½ç›®å½•ã€‚"""
    candidates = []
    home = Path.home()
    candidates.append(home / "Downloads")
    candidates.append(home / "ä¸‹è½½")

    userprofile = os.environ.get("USERPROFILE")
    if userprofile:
        candidates.append(Path(userprofile) / "Downloads")
        candidates.append(Path(userprofile) / "ä¸‹è½½")

    # åªä¿ç•™å­˜åœ¨çš„è·¯å¾„
    return [p for p in candidates if p.exists()]


def is_under_path(path: Path, root: Path) -> bool:
    try:
        return path.resolve().is_relative_to(root.resolve())
    except Exception:
        # å…¼å®¹è€ç‰ˆæœ¬å†™æ³•
        try:
            path.resolve().relative_to(root.resolve())
            return True
        except Exception:
            return False


def normalize_name(name: str) -> str:
    """å»æ‰ç¬¦å·å¹¶ç»Ÿä¸€å¤§å°å†™ï¼Œç”¨äºåç§°ç›¸ä¼¼åº¦åˆ¤æ–­ã€‚"""
    name = name.lower()
    return re.sub(r"[^0-9a-z\u4e00-\u9fff]+", "", name)


_DATE_PATTERNS = [
    # 20250115 / 2025-01-15 / 2025_1_5 / 2025.01.15
    re.compile(r"20\d{2}[-_\.]?\d{1,2}[-_\.]?\d{1,2}"),
    # 2025Q1 / 2025q4
    re.compile(r"20\d{2}\s*[qQ]\s*[1-4]"),
]
_VERSION_PATTERNS = [
    # v1 / v1.2 / v2025.01
    re.compile(r"^v\d+([._-]\d+)*$", re.IGNORECASE),
    re.compile(r"^(ver|version|rev|release)\d*([._-]\d+)*$", re.IGNORECASE),
    # 1.2.3 / 2025.01.15 ç­‰çº¯æ•°å­—ç‚¹åˆ†
    re.compile(r"^\d+(\.\d+){1,4}$"),
]
_NOISE_TOKENS = {
    # è‹±æ–‡å¸¸è§å™ªå£°
    "final", "draft", "copy", "temp", "tmp", "new", "untitled",
    "export", "output", "converted", "scan", "scanned",
    # ä¸­æ–‡å¸¸è§å™ªå£°
    # æ³¨æ„ï¼šä¸è¦æŠŠå¯èƒ½å…·æœ‰è¯­ä¹‰çš„è¯ï¼ˆå¦‚â€œå½’æ¡£â€ï¼‰å½“ä½œå™ªå£°å‰”é™¤ï¼Œå¦åˆ™ä¼šå¯¼è‡´ç›¸ä¼¼åŒ¹é…å¤±è´¥
    "å‰¯æœ¬", "æ‹·è´", "å¤‡ä»½", "æœ€ç»ˆç‰ˆ", "ç»ˆç‰ˆ", "è‰ç¨¿", "å®šç¨¿", "æ–°å»º", "æœªå‘½å",
}


def _split_tokens(name: str) -> List[str]:
    """
    å°†æ–‡ä»¶åæ‹†æˆ tokenï¼šå…¼å®¹ä¸­è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿/ç©ºæ ¼/æ‹¬å·ç­‰ï¼Œä»¥åŠ camelCaseã€‚
    """
    s = name.strip()
    # camelCase è¾¹ç•Œæ’ç©ºæ ¼
    s = re.sub(r"([a-z])([A-Z])", r"\1 \2", s)
    # ç»Ÿä¸€åˆ†éš”ç¬¦ä¸ºç©ºæ ¼
    s = re.sub(r"[^\w\u4e00-\u9fff]+", " ", s, flags=re.UNICODE)
    raw = [t for t in s.split() if t]

    # è¿›ä¸€æ­¥æ‹†åˆ†â€œä¸­æ–‡/è‹±æ–‡ + æ•°å­—â€ç²˜è¿çš„ tokenï¼Œä¾‹å¦‚ï¼šå½’æ¡£16ã€report2025
    tokens: List[str] = []
    for tok in raw:
        parts = re.findall(r"[A-Za-z\u4e00-\u9fff]+|\d+", tok, flags=re.UNICODE)
        tokens.extend(parts if parts else [tok])
    return tokens


def _is_date_like(token: str) -> bool:
    t = token.strip()
    for pat in _DATE_PATTERNS:
        if pat.fullmatch(t) or pat.search(t):
            return True
    return False


def _is_version_like(token: str) -> bool:
    t = token.strip()
    for pat in _VERSION_PATTERNS:
        if pat.fullmatch(t):
            return True
    return False


def _clean_tokens_for_similarity(name: str) -> List[str]:
    tokens = _split_tokens(name)
    cleaned: List[str] = []
    for tok in tokens:
        t = tok.strip().lower()
        if not t:
            continue
        # å»æ‹¬å·åŒ…è£¹çš„çº¯æ•°å­—ï¼š(1) / [2]
        if re.fullmatch(r"[\(\[\{]?\d+[\)\]\}]?", t):
            continue
        if _is_date_like(t):
            continue
        if _is_version_like(t):
            continue
        # å›é€€åˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬ï¼šçº¯æ•°å­—æŒ‰å™ªå£°å¤„ç†ï¼ˆç”¨äºæ›´å¼ºçš„â€œè¯­ä¹‰å + æ—¶é—´å°¾å·´â€åŒ¹é…ï¼‰
        if t.isdigit():
            continue
        # ä¸­æ–‡ token ä¹Ÿå¯èƒ½æ˜¯â€œå‰¯æœ¬â€ç­‰
        if t in _NOISE_TOKENS:
            continue
        # è¯¸å¦‚ x64/arm64/win64 è¿™ç±»å¹³å°ä¿¡æ¯é€šå¸¸æ˜¯å™ªå£°
        if re.fullmatch(r"(x64|x86|arm64|amd64|win\d*|mac|linux)", t):
            continue
        cleaned.append(t)
    return cleaned


def _core_string(tokens: List[str]) -> str:
    """
    å°† token åˆæˆâ€œæ ¸å¿ƒä¸²â€ï¼Œç”¨äºç¼–è¾‘è·ç¦»ï¼›ä¸­æ–‡/è‹±æ–‡ç»Ÿä¸€å°å†™ï¼Œç§»é™¤ç¬¦å·ã€‚
    """
    if not tokens:
        return ""
    joined = " ".join(tokens)
    return normalize_name(joined)


def name_similarity(a: str, b: str) -> float:
    """
    ä¼˜åŒ–åçš„æ–‡ä»¶åç›¸ä¼¼åº¦ï¼š
    - å…ˆç§»é™¤æ—¥æœŸ/ç‰ˆæœ¬/å‰¯æœ¬ç­‰å™ªå£° token
    - å†ç»¼åˆ token Jaccard + æ ¸å¿ƒä¸²ç¼–è¾‘è·ç¦»
    """
    ta = _clean_tokens_for_similarity(a)
    tb = _clean_tokens_for_similarity(b)

    ca = _core_string(ta) or normalize_name(a)
    cb = _core_string(tb) or normalize_name(b)
    if not ca or not cb:
        return 0.0

    seq = SequenceMatcher(None, ca, cb).ratio()

    set_a = set(ta)
    set_b = set(tb)
    if not set_a or not set_b:
        token_j = 0.0
    else:
        inter = len(set_a & set_b)
        union = len(set_a | set_b)
        token_j = inter / union if union else 0.0

    # å­ä¸²åŠ æˆï¼šæ¯”å¦‚â€œæŠ¥å‘Šâ€ vs â€œæŠ¥å‘Šæ›´æ–°â€
    substr_bonus = 0.0
    if ca in cb or cb in ca:
        substr_bonus = 0.05

    score = 0.6 * seq + 0.4 * token_j + substr_bonus
    return min(1.0, max(0.0, score))


def is_recently_accessed(atime: float, days: int) -> bool:
    return (time.time() - atime) <= days * 86400


def is_recently_accessed_hours(atime: float, hours: float) -> bool:
    return (time.time() - atime) <= hours * 3600


def last_activity_ts_by_mtime_ctime(ctime: float, mtime: float) -> float:
    """
    è¿‡ç¨‹æ–‡ä»¶åˆ¤å®šä¸å†ä¾èµ– atimeï¼ˆè®¿é—®æ—¶é—´ï¼‰ã€‚
    ç»Ÿä¸€ç”¨ max(mtime, ctime) ä½œä¸ºâ€œæœ€è¿‘æ´»åŠ¨æ—¶é—´â€ã€‚
    """
    return max(ctime, mtime)


def is_inactive_for_days_by_mtime_ctime(ctime: float, mtime: float, days: float) -> bool:
    """ä»Šå¤© - ä¿®æ”¹æ—¥æœŸ/åˆ›å»ºæ—¥æœŸ > Nå¤©ï¼ˆç”¨ max(mtime, ctime) è®¡ç®—ï¼‰"""
    ts = last_activity_ts_by_mtime_ctime(ctime, mtime)
    return (time.time() - ts) > days * 86400


def used_soon_after_create_by_mtime_ctime(ctime: float, mtime: float, minutes: int) -> bool:
    """
    ä¸‹è½½ç±»è¿‡ç¨‹æ–‡ä»¶çš„â€œåˆ›å»ºå â‰¤30åˆ†é’Ÿå†…è¢«ä½¿ç”¨â€ï¼š
    - (ä¿®æ”¹æ—¥æœŸ - åˆ›å»ºæ—¥æœŸ) â‰¤ 30åˆ†é’Ÿ
      OR
    - åˆ›å»ºæ—¥æœŸ > ä¿®æ”¹æ—¥æœŸï¼ˆæ—¶é—´é¡ºåºå¼‚å¸¸/æ‹·è´è¡Œä¸ºç­‰ï¼‰
    """
    if ctime > mtime:
        return True
    return (mtime - ctime) <= minutes * 60


def opened_within_minutes(ctime: float, atime: float, minutes: int) -> bool:
    if atime < ctime:
        return False
    return (atime - ctime) <= minutes * 60


def recently_used_within_minutes(ctime: float, atime: float, mtime: float, minutes: int) -> bool:
    """åˆ›å»ºåçŸ­æ—¶é—´å†…è¢«ä½¿ç”¨ï¼ˆè®¿é—®æˆ–ä¿®æ”¹ï¼‰"""
    # â€œè¢«ä½¿ç”¨â€çš„å®šä¹‰ï¼šè®¿é—®æ—¶é—´æˆ–ä¿®æ”¹æ—¶é—´ä»»ä¸€æ»¡è¶³å³å¯
    threshold = minutes * 60
    ok_access = atime >= ctime and (atime - ctime) <= threshold
    ok_modify = mtime >= ctime and (mtime - ctime) <= threshold
    return ok_access or ok_modify


def list_editable_sources_nearby(file_path: Path, max_siblings: int = 5) -> List[Path]:
    """åœ¨åŒç›®å½•æˆ–ç›¸é‚»ç›®å½•å¯»æ‰¾å¯ç¼–è¾‘æºæ–‡ä»¶ã€‚"""
    candidates = []
    parent = file_path.parent

    # åŒç›®å½•
    for p in parent.glob("*"):
        if p.is_file() and p.suffix.lower() in EDITABLE_SOURCE_EXTS:
            candidates.append(p)

    # çˆ¶ç›®å½•ä¸‹çš„ç›¸é‚»ç›®å½•ï¼ˆé™åˆ¶æ•°é‡é¿å…æ‰«æå¤ªå¤§ï¼‰
    parent_parent = parent.parent
    if parent_parent.exists():
        siblings = [d for d in parent_parent.iterdir() if d.is_dir()]
        for d in siblings[:max_siblings]:
            for p in d.glob("*"):
                if p.is_file() and p.suffix.lower() in EDITABLE_SOURCE_EXTS:
                    candidates.append(p)

    return candidates


def find_similar_named_folder(file_path: Path) -> Tuple[Optional[Path], float]:
    """åœ¨åŒä¸€çˆ¶ç›®å½•ä¸‹æŸ¥æ‰¾åŒå/ç›¸ä¼¼æ–‡ä»¶å¤¹ã€‚"""
    parent = file_path.parent
    best_match = None
    best_score = 0.0
    for p in parent.iterdir():
        if p.is_dir():
            score = name_similarity(p.name, file_path.stem)
            if score > best_score:
                best_score = score
                best_match = p
    return best_match, best_score


def build_file_info(path: Path) -> FileInfo:
    st = path.stat()
    return FileInfo(
        path=path,
        name=path.name,
        stem=path.stem,
        ext=path.suffix.lower(),
        parent=path.parent,
        size=st.st_size,
        ctime=st.st_ctime,
        mtime=st.st_mtime,
        atime=st.st_atime,
    )


def evaluate_archive_file(
    info: FileInfo,
) -> Optional[Dict]:
    if info.ext not in ARCHIVE_EXTS:
        return None

    folder_match, score = find_similar_named_folder(info.path)
    has_extract_folder = bool(folder_match and score >= 0.9)
    if not has_extract_folder:
        return None

    # æœ€åæ¡ä»¶ï¼šå¤§äº 1 å¤©æœªè®¿é—®ï¼ˆä»Šå¤© - ä¿®æ”¹æ—¥æœŸ/åˆ›å»ºæ—¥æœŸ > 1å¤©ï¼‰
    if not is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 1):
        return None

    return {
        "category": "archive_container",
        "path": str(info.path),
        "evidence": {
            "extract_folder": str(folder_match) if folder_match else "",
            "folder_match_score": round(score, 3),
        },
    }


def evaluate_installer_file(
    info: FileInfo,
) -> Optional[Dict]:
    if info.ext not in INSTALLER_EXTS:
        return None

    # æœ€åæ¡ä»¶ï¼šå¤§äº 1 å¤©æœªè®¿é—®ï¼ˆä»Šå¤© - ä¿®æ”¹æ—¥æœŸ/åˆ›å»ºæ—¥æœŸ > 1å¤©ï¼‰
    if not is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 1):
        return None

    return {
        "category": "installer",
        "path": str(info.path),
    }


def evaluate_document_export(
    info: FileInfo,
) -> Optional[Dict]:
    if info.ext != ".pdf":
        return None

    # å¿…è¦æ¡ä»¶ï¼šå­˜åœ¨ç›¸åŒæˆ–ç›¸ä¼¼åç§°çš„å¯ç¼–è¾‘æºæ–‡ä»¶
    similar_source = None
    similar_score = 0.0
    sources = list_editable_sources_nearby(info.path)
    for src in sources:
        score = name_similarity(info.stem, src.stem)
        if score > similar_score:
            similar_score = score
            similar_source = src

    if similar_score < 0.9:
        return None

    # æœ€åæ¡ä»¶ï¼šå¤§äº 3 å¤©æœªè®¿é—®ï¼ˆä»Šå¤© - ä¿®æ”¹æ—¥æœŸ/åˆ›å»ºæ—¥æœŸ > 3å¤©ï¼‰
    if not is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 3):
        return None

    return {
        "category": "document_export",
        "path": str(info.path),
        "evidence": {
            "similar_source": str(similar_source) if similar_source else "",
            "name_similarity": round(similar_score, 3)
            },
    }


def evaluate_single_use_download(
    info: FileInfo,
) -> Optional[Dict]:
    if info.ext in ARCHIVE_EXTS or info.ext in INSTALLER_EXTS:
        return None

    # å¿…è¦æ¡ä»¶ 1ï¼šåˆ›å»ºå â‰¤ 30 åˆ†é’Ÿå†…è¢«ä½¿ç”¨ï¼ˆåŸºäº mtime/ctimeï¼‰
    if not used_soon_after_create_by_mtime_ctime(info.ctime, info.mtime, OPEN_WITHIN_MINUTES):
        return None

    # å¿…è¦æ¡ä»¶ 2ï¼šå¤§äº 3 å¤©æœªè®¿é—®ï¼ˆä»Šå¤© - ä¿®æ”¹æ—¥æœŸ/åˆ›å»ºæ—¥æœŸ > 3å¤©ï¼‰
    if not is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 1):
        return None

    return {
        "category": "downloads",
        "path": str(info.path),
    }


def scan_files(target_dir: Path, recursive: bool = False) -> List[FileInfo]:
    if recursive:
        files = [p for p in target_dir.rglob("*") if p.is_file()]
    else:
        files = [p for p in target_dir.iterdir() if p.is_file()]
    return [build_file_info(p) for p in files]


def find_process_files(
    target_dir: Path,
    recursive: bool = False,
    debug: bool = False,
) -> List[Dict]:
    results = []
    infos = scan_files(target_dir, recursive=recursive)
    if debug:
        _safe_print(f"[DEBUG] ç›®æ ‡ç›®å½•: {target_dir.resolve()}")
        _safe_print(f"[DEBUG] é€’å½’æ‰«æ: {'æ˜¯' if recursive else 'å¦'}")
        _safe_print(f"[DEBUG] æ‰«æåˆ°æ–‡ä»¶æ•°: {len(infos)}")
        if len(infos) == 0:
            _safe_print("[DEBUG] æœªæ‰«æåˆ°ä»»ä½•æ–‡ä»¶ï¼ˆå¯èƒ½ç›®å½•ä¸ºç©ºï¼Œæˆ–åªæœ‰å­æ–‡ä»¶å¤¹ä¸”æ— æ–‡ä»¶ï¼‰")

    for info in infos:
        if debug:
            now = time.time()
            cdt = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(info.ctime))
            mdt = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(info.mtime))
            adt = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(info.atime))
            dm_min = (info.mtime - info.ctime) / 60.0
            last_ts = last_activity_ts_by_mtime_ctime(info.ctime, info.mtime)
            last_dt = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(last_ts))
            inactive_days = (now - last_ts) / 86400.0
            _safe_print(
                f"\n[DEBUG] {info.path}\n"
                f"  ctime={cdt}  mtime={mdt}  atime={adt}\n"
                f"  last_activity(ctime/mtime)={last_dt}  inactive={inactive_days:.2f}d  (mtime-ctime)={dm_min:.2f}min"
            )

        matched = False
        # 1) å‹ç¼©åŒ…ç±»
        res = evaluate_archive_file(info)
        if res:
            results.append(res)
            matched = True
        elif debug and info.ext in ARCHIVE_EXTS:
            folder_match, score = find_similar_named_folder(info.path)
            _safe_print(
                f"  [archive_container] folder_match_score={score:.3f} "
                f"has_folder={'Y' if (folder_match and score >= 0.9) else 'N'} "
                f"inactive_>1d={'Y' if is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 1) else 'N'}"
            )

        if matched:
            continue

        # 2) å®‰è£…åŒ…ç±»
        res = evaluate_installer_file(info)
        if res:
            results.append(res)
            matched = True
        elif debug and info.ext in INSTALLER_EXTS:
            _safe_print(
                f"  [installer] inactive_>1d={'Y' if is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 1) else 'N'}"
            )

        if matched:
            continue

        # 3) æ–‡æ¡£å¯¼å‡ºç±»
        res = evaluate_document_export(info)
        if res:
            results.append(res)
            matched = True
        elif debug and info.ext == ".pdf":
            similar_source = None
            similar_score = 0.0
            sources = list_editable_sources_nearby(info.path)
            for src in sources:
                score = name_similarity(info.stem, src.stem)
                if score > similar_score:
                    similar_score = score
                    similar_source = src
            _safe_print(
                f"  [document_export] best_name_similarity={similar_score:.3f} "
                f"has_source={'Y' if similar_source else 'N'} "
                f"inactive_>3d={'Y' if is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 3) else 'N'} "
                f"best_source={similar_source}"
            )

        if matched:
            continue

        # 4) ä¸‹è½½å³ç”¨ç±»
        res = evaluate_single_use_download(info)
        if res:
            results.append(res)
            matched = True
        elif debug:
            used_30m = used_soon_after_create_by_mtime_ctime(info.ctime, info.mtime, OPEN_WITHIN_MINUTES)
            inactive_3d = is_inactive_for_days_by_mtime_ctime(info.ctime, info.mtime, 3)
            _safe_print(
                f"  [downloads] used_within_30m={'Y' if used_30m else 'N'} "
                f"inactive_>3d={'Y' if inactive_3d else 'N'}"
            )
    return results


def process_directory(target_dir, log_callback=None, recursive: bool = True, debug: bool = False) -> List[Dict]:
    """
    ä¸å…¶å®ƒæ¨¡å—ä¿æŒä¸€è‡´çš„å…¥å£ï¼šæ¥æ”¶ç›®æ ‡ç›®å½•å¹¶è¿”å›â€œç»„å¡ç‰‡â€ç»“æœåˆ—è¡¨ï¼Œä¾›å‰ç«¯æ¸²æŸ“ã€‚

    è¾“å‡ºç»“æ„ï¼ˆæ¯ç»„ï¼‰ï¼š
    - type: "process"
    - group_id
    - label: åˆ†ç±»åç§°
    - file_size_mb / fileSize
    - need_cleanup
    - files: [{path,name,size,mtime,suggestion,category,evidence}]
    - analysis: è§£é‡Šæ–‡æœ¬
    """
    def log(msg: str):
        if log_callback:
            log_callback(msg)
        else:
            _safe_print(msg)

    base = Path(target_dir)
    if not base.exists() or not base.is_dir():
        log(f"âŒ ç›®å½•ä¸å­˜åœ¨æˆ–ä¸å¯è®¿é—®ï¼š{base}")
        return []

    CATEGORY_LABEL = {
        "archive_container": "å‹ç¼©åŒ…ï¼ˆå·²è§£å‹å¯åˆ é™¤å‹ç¼©åŒ…ï¼‰",
        "installer": "å®‰è£…åŒ…ï¼ˆå®‰è£…åå¯åˆ é™¤ï¼‰",
        "document_export": "å¯¼å‡ºæ–‡ä»¶ï¼ˆæœ‰æºæ–‡ä»¶å¯åˆ é™¤å¯¼å‡ºä»¶ï¼‰",
        "downloads": "ä¸‹è½½å³ç”¨ï¼ˆçŸ­æœŸç”¨è¿‡ã€è¿‘æœŸæœªå†ä½¿ç”¨ï¼‰",
    }
    CATEGORY_SUGGESTION = {
        "archive_container": "ğŸ—‘ å»ºè®®åˆ é™¤ï¼ˆå·²å­˜åœ¨è§£å‹æ–‡ä»¶å¤¹ï¼‰",
        "installer": "ğŸ—‘ å»ºè®®åˆ é™¤ï¼ˆå®‰è£…åŒ…ï¼‰",
        "document_export": "ğŸ—‘ å»ºè®®åˆ é™¤ï¼ˆå­˜åœ¨å¯ç¼–è¾‘æºæ–‡ä»¶ï¼‰",
        "downloads": "ğŸ—‘ å»ºè®®æ¸…ç†ï¼ˆä¸‹è½½å³ç”¨ï¼‰",
    }

    log(f"ğŸš€ å¼€å§‹æ‰«æè¿‡ç¨‹æ–‡ä»¶: {str(base)} (é€’å½’: {'æ˜¯' if recursive else 'å¦'})")
    raw = find_process_files(base, recursive=recursive, debug=debug)
    if not raw:
        log("âœ… æœªå‘ç°è¿‡ç¨‹æ–‡ä»¶")
        return []

    # è¡¥é½å‰ç«¯éœ€è¦çš„ file å­—æ®µ
    groups: Dict[str, List[Dict]] = {}
    for item in raw:
        category = item.get("category") or "process"
        path_str = item.get("path") or ""
        if not path_str:
            continue

        p = Path(path_str)
        try:
            st = p.stat()
            size = int(getattr(st, "st_size", 0) or 0)
            mtime = float(getattr(st, "st_mtime", 0.0) or 0.0)
        except OSError:
            size = 0
            mtime = 0.0

        file_obj = {
            "path": str(p),
            "name": p.name,
            "size": size,
            "mtime": mtime,
            "suggestion": CATEGORY_SUGGESTION.get(category, "ğŸ—‘ å»ºè®®æ¸…ç†ï¼ˆè¿‡ç¨‹æ–‡ä»¶ï¼‰"),
            "category": category,
            "evidence": item.get("evidence", {}),
        }
        groups.setdefault(category, []).append(file_obj)

    # å›ºå®šè¾“å‡ºé¡ºåºï¼ˆæ›´ç¬¦åˆç”¨æˆ·ç†è§£ï¼‰
    ordered_categories = ["archive_container", "installer", "document_export", "downloads"]
    # è¡¥å……æœªçŸ¥åˆ†ç±»
    for c in groups.keys():
        if c not in ordered_categories:
            ordered_categories.append(c)

    results: List[Dict] = []
    gid = 1
    for category in ordered_categories:
        files = groups.get(category)
        if not files:
            continue
        total_mb = round(sum(f.get("size", 0) for f in files) / (1024 * 1024), 2)
        label = CATEGORY_LABEL.get(category, "è¿‡ç¨‹æ–‡ä»¶")
        results.append(
            {
                "type": "process",
                "group_id": gid,
                "label": label,
                "fileSize": total_mb,
                "file_size_mb": total_mb,
                "need_cleanup": True,
                "files": files,
                "analysis": f"è¯†åˆ«åˆ° {len(files)} ä¸ªâ€œ{label}â€ç±»å‹çš„è¿‡ç¨‹æ–‡ä»¶ï¼Œå»ºè®®æŒ‰éœ€æ¸…ç†æˆ–å½’æ¡£ã€‚",
                "criteria": {
                    "recursive": bool(recursive),
                    "category": category,
                },
            }
        )
        gid += 1

    log(f"âœ… è¿‡ç¨‹æ–‡ä»¶æ‰«æå®Œæˆï¼š{sum(len(v) for v in groups.values())} ä¸ªæ–‡ä»¶ï¼Œ{len(results)} ç»„")
    return results


def parse_args():
    parser = argparse.ArgumentParser(description="æŸ¥æ‰¾æ–‡ä»¶å¤¹å†…çš„è¿‡ç¨‹æ–‡ä»¶")
    parser.add_argument("target_dir", type=str, help="è¦æ‰«æçš„ç›®å½•")
    parser.add_argument("--recursive", action="store_true", help="é€’å½’æ‰«æå­æ–‡ä»¶å¤¹ï¼ˆé»˜è®¤ä¸é€’å½’ï¼‰")
    parser.add_argument("--debug", action="store_true", help="è¾“å‡ºæ¯ä¸ªæ–‡ä»¶çš„åˆ¤å®šç»†èŠ‚ï¼ˆç”¨äºæ’æŸ¥æœªå‘½ä¸­åŸå› ï¼‰")
    return parser.parse_args()


def main():
    args = parse_args()
    target_dir = Path(args.target_dir)
    if not target_dir.exists():
        _safe_print(f"âŒ ç›®å½•ä¸å­˜åœ¨ï¼š{target_dir}")
        sys.exit(1)

    results = find_process_files(
        target_dir=target_dir,
        recursive=args.recursive,
        debug=args.debug,
    )

    _safe_print(f"âœ… å…±å‘ç° {len(results)} ä¸ªè¿‡ç¨‹æ–‡ä»¶")
    _safe_print(json.dumps(results, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
