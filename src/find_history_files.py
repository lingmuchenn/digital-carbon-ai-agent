import argparse
import json
import os
import sys
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Callable, Dict, Iterable, List, Optional, Tuple


"""
find_history_files.py

æ‰«æç”¨æˆ·è¾“å…¥çš„æ–‡ä»¶å¤¹ï¼Œä¾æ®æ–‡ä»¶å…ƒä¿¡æ¯åˆ¤å®šâ€œå†å²æ–‡ä»¶â€ï¼š
1) è¶…è¿‡ N ä¸ªæœˆæœªä¿®æ”¹ï¼ˆmtime è·ä»Šè¶…è¿‡é˜ˆå€¼ï¼‰
   ä¸” åˆ›å»ºè‡³ä»Šè¶…è¿‡ N ä¸ªæœˆï¼ˆctime è·ä»Šè¶…è¿‡é˜ˆå€¼ï¼‰
   - é»˜è®¤ 6 ä¸ªæœˆï¼›é˜ˆå€¼å¯ç”±ç”¨æˆ·å‚æ•°ä¿®æ”¹
   - æ³¨æ„ï¼šWindows ä¸Š st_ctime é€šå¸¸ä»£è¡¨åˆ›å»ºæ—¶é—´ï¼›Linux/macOS ä¸Šå¯èƒ½ä»£è¡¨ inode/change timeï¼ˆå—ç³»ç»Ÿå½±å“ï¼‰
2) æ–‡ä»¶è·¯å¾„å±‚çº§ <= max_depthï¼ˆåŒ…å«æ–‡ä»¶åå±‚çº§ï¼‰ï¼Œé¡¶å±‚ä¸ºç”¨æˆ·è¾“å…¥ç›®å½•
   - ä¾‹å¦‚ max_depth=3ï¼š
     - æ ¹ç›®å½•ä¸‹ file.txt => 1 å±‚ âœ…
     - å­ç›®å½•/file.txt => 2 å±‚ âœ…
     - å­/å­/file.txt => 3 å±‚ âœ…
     - å­/å­/å­/file.txt => 4 å±‚ âŒ

æœ¬æ–‡ä»¶æä¾›ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š
- ä½œä¸ºæ¨¡å—ï¼šprocess_directory(target_dir, log_callback=...) -> è¿”å›å‰ç«¯å¯ç”¨çš„ç»“æœåˆ—è¡¨
- å‘½ä»¤è¡Œï¼špython find_history_files.py <target_dir> --inactive-months 6 --age-months 6 --max-depth 3
"""


SECONDS_PER_DAY = 86400


@dataclass(frozen=True)
class HistoryRule:
    inactive_months: int = 6
    age_months: int = 6
    max_depth: int = 3  # åŒ…å«æ–‡ä»¶åå±‚çº§
    chunk_size: int = 50  # ç»“æœæŒ‰å¡ç‰‡åˆ†ç»„ï¼Œé¿å…å•ç»„è¿‡å¤§

    @property
    def inactive_days(self) -> int:
        return max(0, int(self.inactive_months) * 30)

    @property
    def age_days(self) -> int:
        return max(0, int(self.age_months) * 30)


def _safe_print(msg: str) -> None:
    """é¿å… Windows æ§åˆ¶å°ç¼–ç é—®é¢˜å¯¼è‡´æ‰“å°å´©æºƒã€‚"""
    try:
        print(msg)
    except UnicodeEncodeError:
        enc = getattr(sys.stdout, "encoding", None) or "utf-8"
        try:
            safe_msg = msg.encode(enc, errors="replace").decode(enc, errors="replace")
        except Exception:
            safe_msg = msg.encode("utf-8", errors="replace").decode("utf-8", errors="replace")
        print(safe_msg)


def _format_date(ts: float) -> str:
    try:
        return datetime.fromtimestamp(ts).strftime("%Y-%m-%d")
    except Exception:
        return ""


def _iter_files_limited_depth(base_dir: Path, max_depth_including_filename: int) -> Iterable[Path]:
    """
    åªéå† base_dir ä¸‹â€œç›¸å¯¹å±‚çº§ï¼ˆå«æ–‡ä»¶åï¼‰<= max_depthâ€çš„æ–‡ä»¶ã€‚
    ä½¿ç”¨ os.walk(topdown=True) è¿›è¡Œç›®å½•å‰ªæï¼Œé¿å…æ·±å±‚æ‰«ææµªè´¹æ—¶é—´ã€‚
    """
    base_dir = base_dir.resolve()
    # å…è®¸çš„æœ€å¤§â€œç›®å½•æ·±åº¦â€ï¼ˆä¸å«æ–‡ä»¶åï¼‰ï¼šmax_depth-1
    max_dir_depth = max(0, int(max_depth_including_filename) - 1)

    for root, dirs, files in os.walk(str(base_dir), topdown=True):
        try:
            rel_root = Path(root).resolve().relative_to(base_dir)
            dir_depth = 0 if str(rel_root) == "." else len(rel_root.parts)
        except Exception:
            # æ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„æ—¶ï¼Œä¿å®ˆå¤„ç†ï¼šä¸å‰ªæä½†ä»ç»§ç»­
            dir_depth = 0

        # ç›®å½•æœ¬èº«æ·±åº¦å·²ç»è¶…è¿‡å…è®¸èŒƒå›´ï¼šç›´æ¥å‰ªæ
        if dir_depth > max_dir_depth:
            dirs[:] = []
            continue

        # å½“å‰ç›®å½•åˆšå¥½åœ¨æœ€å¤§ç›®å½•æ·±åº¦ï¼šä¸å†æ·±å…¥å­ç›®å½•
        if dir_depth == max_dir_depth:
            dirs[:] = []

        for name in files:
            path = Path(root) / name
            # æ–‡ä»¶å±‚çº§ = ç›®å½•æ·±åº¦ + 1ï¼ˆæ–‡ä»¶åï¼‰
            file_depth = dir_depth + 1
            if file_depth <= max_depth_including_filename:
                yield path


def _is_history_file(st: os.stat_result, now_ts: float, rule: HistoryRule) -> Tuple[bool, Dict[str, int]]:
    """
    å†å²æ–‡ä»¶åˆ¤å®šï¼šè¶…è¿‡ rule.inactive_days æœªä¿®æ”¹ï¼Œä¸”åˆ›å»ºè‡³ä»Šè¶…è¿‡ rule.age_daysã€‚
    è¿”å›ï¼š(æ˜¯å¦å‘½ä¸­, è¯Šæ–­ä¿¡æ¯)
    """
    try:
        days_since_modify = int((now_ts - st.st_mtime) / SECONDS_PER_DAY)
    except Exception:
        days_since_modify = 0
    try:
        days_since_create = int((now_ts - st.st_ctime) / SECONDS_PER_DAY)
    except Exception:
        days_since_create = 0

    ok_modify = days_since_modify >= rule.inactive_days
    ok_create = days_since_create >= rule.age_days
    return (ok_modify and ok_create), {
        "days_since_modify": days_since_modify,
        "days_since_create": days_since_create,
    }


def _chunk_list(items: List[Dict], chunk_size: int) -> List[List[Dict]]:
    if chunk_size <= 0:
        return [items]
    return [items[i : i + chunk_size] for i in range(0, len(items), chunk_size)]


def find_history_files(
    target_dir: Path,
    rule: HistoryRule,
    log: Optional[Callable[[str], None]] = None,
) -> List[Dict]:
    """
    æ‰«æå¹¶è¿”å›å†å²æ–‡ä»¶åˆ—è¡¨ï¼ˆæœªåˆ†ç»„ï¼‰ã€‚
    æ¯ä¸ªå…ƒç´ ä¸ºå‰ç«¯å¯ç”¨çš„ file å¯¹è±¡ï¼š{path,name,size,mtime,suggestion,...}
    """
    def _log(msg: str) -> None:
        if log:
            log(msg)
        else:
            _safe_print(msg)

    target_dir = Path(target_dir)
    if not target_dir.exists() or not target_dir.is_dir():
        raise ValueError(f"Invalid directory: {target_dir}")

    now_ts = time.time()
    _log(
        f"ğŸš€ å¼€å§‹æ‰«æå†å²æ–‡ä»¶: {str(target_dir)} "
        f"(è§„åˆ™: æœªä¿®æ”¹â‰¥{rule.inactive_months}ä¸ªæœˆ & åˆ›å»ºâ‰¥{rule.age_months}ä¸ªæœˆ, æœ€å¤§å±‚çº§â‰¤{rule.max_depth})"
    )

    matched_files: List[Dict] = []
    scanned = 0

    for path in _iter_files_limited_depth(target_dir, rule.max_depth):
        scanned += 1
        try:
            st = path.stat()
        except OSError:
            continue

        ok, diag = _is_history_file(st, now_ts, rule)
        if not ok:
            continue

        size_bytes = int(getattr(st, "st_size", 0) or 0)
        suggestion = "ğŸ—‚ å»ºè®®å½’æ¡£/æ¸…ç†ï¼ˆé•¿æœŸæœªä¿®æ”¹ï¼‰"
        matched_files.append(
            {
                "path": str(path),
                "name": path.name,
                "size": size_bytes,
                "mtime": float(getattr(st, "st_mtime", 0.0) or 0.0),
                "suggestion": suggestion,
                # ä¾¿äºè°ƒè¯•/è§£é‡Šï¼ˆå‰ç«¯ä¸ä¸€å®šä¼šå±•ç¤ºï¼‰
                "days_since_modify": diag["days_since_modify"],
                "days_since_create": diag["days_since_create"],
            }
        )

    matched_files.sort(key=lambda x: (x.get("mtime", 0.0), x.get("path", "")))
    _log(f"ğŸ“„ æ‰«ææ–‡ä»¶æ•°ï¼ˆå—å±‚çº§é™åˆ¶ï¼‰: {scanned}")
    _log(f"âœ… å‘½ä¸­å†å²æ–‡ä»¶: {len(matched_files)}")
    return matched_files


def process_directory(target_dir, log_callback=None, rule: Optional[HistoryRule] = None) -> List[Dict]:
    """
    ä¸å…¶å®ƒæ¨¡å—ä¿æŒä¸€è‡´çš„å…¥å£ï¼šæ¥æ”¶ç›®æ ‡ç›®å½•å¹¶è¿”å›ç»“æœåˆ—è¡¨ã€‚
    è¿”å›ç»“æ„è®¾è®¡ä¸ºâ€œç»„å¡ç‰‡â€å½¢å¼ï¼Œæ–¹ä¾¿å‰ç«¯åƒé‡å¤æ–‡ä»¶ä¸€æ ·æ¸²æŸ“ã€‚
    """
    def log(msg):
        if log_callback:
            log_callback(msg)
        else:
            _safe_print(msg)

    try:
        rule = rule or HistoryRule()
        folder_path = Path(target_dir)
        files = find_history_files(folder_path, rule=rule, log=log)
        if not files:
            log("âœ… æœªå‘ç°å†å²æ–‡ä»¶")
            return []

        chunks = _chunk_list(files, rule.chunk_size)
        results: List[Dict] = []
        for idx, chunk in enumerate(chunks, start=1):
            total_mb = round(sum(f.get("size", 0) for f in chunk) / (1024 * 1024), 2)
            newest_mtime = max((f.get("mtime", 0.0) for f in chunk), default=0.0)
            oldest_mtime = min((f.get("mtime", 0.0) for f in chunk), default=0.0)

            results.append(
                {
                    "type": "history",
                    "group_id": idx,
                    "fileSize": total_mb,
                    "file_size_mb": total_mb,  # å…¼å®¹ duplicate çš„å­—æ®µå‘½å
                    "need_cleanup": True,
                    "files": chunk,
                    "analysis": (
                        f"å‘½ä¸­è§„åˆ™ï¼šæœªä¿®æ”¹â‰¥{rule.inactive_months}ä¸ªæœˆ ä¸” åˆ›å»ºâ‰¥{rule.age_months}ä¸ªæœˆï¼Œ"
                        f"è·¯å¾„å±‚çº§â‰¤{rule.max_depth}ã€‚"
                        f"æœ¬ç»„å…± {len(chunk)} ä¸ªæ–‡ä»¶ï¼Œä¿®æ”¹æ—¶é—´èŒƒå›´ï¼š{_format_date(oldest_mtime)} ~ {_format_date(newest_mtime)}ã€‚"
                    ),
                    "criteria": {
                        "inactive_months": rule.inactive_months,
                        "age_months": rule.age_months,
                        "max_depth": rule.max_depth,
                        "chunk_size": rule.chunk_size,
                    },
                }
            )

        log(f"ğŸ“¦ å·²ç”Ÿæˆ {len(results)} ç»„å†å²æ–‡ä»¶ç»“æœï¼ˆæ¯ç»„â‰¤{rule.chunk_size}ä¸ªï¼‰")
        return results

    except Exception as e:
        log(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        return []


def parse_args():
    parser = argparse.ArgumentParser(description="æŸ¥æ‰¾æ–‡ä»¶å¤¹å†…çš„å†å²æ–‡ä»¶ï¼ˆåŸºäºå…ƒä¿¡æ¯ + å±‚çº§é™åˆ¶ï¼‰")
    parser.add_argument("target_dir", type=str, help="è¦æ‰«æçš„ç›®å½•")
    parser.add_argument("--inactive-months", type=int, default=6, help="æœªä¿®æ”¹é˜ˆå€¼ï¼ˆæœˆï¼‰ï¼Œé»˜è®¤ 6")
    parser.add_argument("--age-months", type=int, default=6, help="åˆ›å»ºè‡³ä»Šé˜ˆå€¼ï¼ˆæœˆï¼‰ï¼Œé»˜è®¤ 6")
    parser.add_argument("--max-depth", type=int, default=3, help="æœ€å¤§è·¯å¾„å±‚çº§ï¼ˆå«æ–‡ä»¶åï¼‰ï¼Œé»˜è®¤ 3")
    parser.add_argument("--chunk-size", type=int, default=50, help="è¾“å‡ºåˆ†ç»„æ¯ç»„æœ€å¤šæ–‡ä»¶æ•°ï¼Œé»˜è®¤ 50")
    return parser.parse_args()


def main():
    args = parse_args()
    target_dir = Path(args.target_dir)
    if not target_dir.exists():
        _safe_print(f"âŒ ç›®å½•ä¸å­˜åœ¨ï¼š{target_dir}")
        sys.exit(1)

    rule = HistoryRule(
        inactive_months=args.inactive_months,
        age_months=args.age_months,
        max_depth=args.max_depth,
        chunk_size=args.chunk_size,
    )
    results = process_directory(target_dir, rule=rule)
    _safe_print(json.dumps(results, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

